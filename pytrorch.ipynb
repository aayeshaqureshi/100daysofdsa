{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdEaF/Duw2qXUpIH0uyT78",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayeshaqureshi/100daysofdsa/blob/main/pytrorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "what_were_covering = {1: \"data (prepare and load)\",\n",
        "    2: \"build model\",\n",
        "    3: \"fitting the model to data (training)\",\n",
        "    4: \"making predictions and evaluating a model (inference)\",\n",
        "    5: \"saving and loading a model\",\n",
        "    6: \"putting it all together\"\n",
        "}"
      ],
      "metadata": {
        "id": "45d9EB30Vgls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rJ7afmSjVD9J",
        "outputId": "35b55484-937f-450e-f84f-8cc03f126b28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "# check the version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparing and Loading\n"
      ],
      "metadata": {
        "id": "3WwvlVGYXQKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.7\n",
        "bias = 0.3\n",
        "#create data\n",
        "start=0\n",
        "end=1\n",
        "step=0.02\n",
        "X= torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y=weight*X+ bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6y4kxHtWEH3",
        "outputId": "ca164c13-46a6-43a3-daa0-69a67569b36f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]), tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data into training and testing sets\n",
        "train_split= int(0.8*len(X))\n",
        "X_train, y_train=X[:train_split], y[:train_split]\n",
        "X_test, y_test= X[train_split:], y[train_split:]\n",
        "\n",
        "\n",
        "len(X_train),len(y_train), len(X_test), len(y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7iImheLXVaS",
        "outputId": "d73523b1-a9e5-4e63-cd32-67cd9ee56379"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visulazing the data we have created \n",
        "def plot_predictions(train_data=X_train, \n",
        "                     train_labels=y_train, \n",
        "                     test_data=X_test, \n",
        "                     test_labels=y_test, \n",
        "                     predictions=None):\n",
        "  plt.figure(figsize=(10,7))\n",
        "  #plot trainign data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label= \"Training data\")\n",
        "  #plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "  if predictions is not None:\n",
        "    #plot the predictions in red-testing data\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"predictions\")\n",
        "  plt.legend(prop={\"size\":14});\n",
        "\n",
        "    \n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "T__CXZDjXVVq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "4Y8ZBclAXVUT",
        "outputId": "4154e4e1-6b70-4ef5-d4fe-aebf4d2c755e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# buiilding a model to predict the green dots using the blue dots \n",
        "#create a Linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights=nn.Parameter(torch.randn(1, dtype= torch.float),requires_grad= True)\n",
        "    self.bias= nn.Parameter(torch.randn(1, dtype=torch.float),requires_grad= True)\n",
        "  def forward(self, x:torch.Tensor)->torch.Tensor:\n",
        "    return self.weights*x+ self.bias\n",
        "\n"
      ],
      "metadata": {
        "id": "A7KlRgfxWEF6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a model instance with the class we have made and check its parameters \n",
        "torch.manual_seed(42)\n",
        "model_0= LinearRegressionModel()\n",
        "\n",
        "#check the nn parameters \n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7Xo7bO_WEC8",
        "outputId": "fa105125-6663-4f0c-f26b-f8fd9edf86c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True), Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_VAosnMifmu",
        "outputId": "2fdc2116-35d5-4de0-e83e-53040c38290d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#makinf predictions using the inference model\n",
        "with torch.inference_mode():\n",
        "  y_preds= model_0(X_test)\n"
      ],
      "metadata": {
        "id": "U0ceS8ksifir"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the predictions\n",
        "print(f\"Number of testing samples: {len(X_test)}\") \n",
        "print(f\"Number of predictions made: {len(y_preds)}\")\n",
        "print(f\"Predicted values:\\n{y_preds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJnmwenVjOjj",
        "outputId": "a81a4b3d-60fd-46b3-d6e4-24f7ae6294ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing samples: 10\n",
            "Number of predictions made: 10\n",
            "Predicted values:\n",
            "tensor([[0.3982],\n",
            "        [0.4049],\n",
            "        [0.4116],\n",
            "        [0.4184],\n",
            "        [0.4251],\n",
            "        [0.4318],\n",
            "        [0.4386],\n",
            "        [0.4453],\n",
            "        [0.4520],\n",
            "        [0.4588]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Y1TewHJgjOg2",
        "outputId": "df0e5598-07be-43b5-a931-5ccb083c01ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test- y_preds "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGJAJR5vjOfN",
        "outputId": "dae01a0c-fa07-4fcd-e800-58fc742e4e95"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4618],\n",
              "        [0.4691],\n",
              "        [0.4764],\n",
              "        [0.4836],\n",
              "        [0.4909],\n",
              "        [0.4982],\n",
              "        [0.5054],\n",
              "        [0.5127],\n",
              "        [0.5200],\n",
              "        [0.5272]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a loss function and optimizer in pytorch \n",
        "\n",
        "loss_fn= nn.L1Loss()\n",
        "# create the optimzer \n",
        "optimizer= torch.optim.SGD(params= model_0.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "wuDjTjM4jObE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a training and testing loop\n",
        "#training \n",
        "#forward pass--> calculate the loss--> zero gradients--> perform backpropagation on the loss--> update the optimizer \n",
        "#testing \n",
        "# forward pass--> calculate the loss--> calculate evaluation metrics(optional)\n"
      ],
      "metadata": {
        "id": "qVY2sm8ijOZX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "#set the number of epochs \n",
        "epochs=100\n",
        "#creating empty loss lists to track values \n",
        "train_loss_values=[]\n",
        "test_loss_values=[]\n",
        "epoch_count=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  ###training \n",
        "  #put model in training mode \n",
        "  model_0.train()\n",
        "  #forward pass on the training data \n",
        "  y_pred= model_0(X_train)\n",
        "  print(y_pred)\n",
        "  #2. caluclate the loss\n",
        "  loss= loss_fn(y_pred, y_train)\n",
        "  # 3. zero grad of the optimizer\n",
        "  optimizer.zero_grad()\n",
        "  #4. loss backwards\n",
        "  loss.backward()\n",
        "  #5. progress the optimizer \n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "  ###testing \n",
        "  #put the model in evaluation mode\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred= model_0(X_test)\n",
        "    #2. calculate the loss on test data\n",
        "    test_loss= loss_fn(test_pred, y_test.type(torch.float))\n",
        "\n",
        "\n",
        "    if epoch%10 ==0:\n",
        "      epoch_count.append(epoch)\n",
        "      train_loss_values.append(loss.detach().numpy())\n",
        "      test_loss_values.append(test_loss.detach().numpy())\n",
        "      print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiDST4FQitAI",
        "outputId": "1960569f-53e2-4f0e-b1ee-30a6e47785af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1288],\n",
            "        [0.1355],\n",
            "        [0.1423],\n",
            "        [0.1490],\n",
            "        [0.1557],\n",
            "        [0.1625],\n",
            "        [0.1692],\n",
            "        [0.1759],\n",
            "        [0.1827],\n",
            "        [0.1894],\n",
            "        [0.1961],\n",
            "        [0.2029],\n",
            "        [0.2096],\n",
            "        [0.2163],\n",
            "        [0.2231],\n",
            "        [0.2298],\n",
            "        [0.2366],\n",
            "        [0.2433],\n",
            "        [0.2500],\n",
            "        [0.2568],\n",
            "        [0.2635],\n",
            "        [0.2702],\n",
            "        [0.2770],\n",
            "        [0.2837],\n",
            "        [0.2904],\n",
            "        [0.2972],\n",
            "        [0.3039],\n",
            "        [0.3106],\n",
            "        [0.3174],\n",
            "        [0.3241],\n",
            "        [0.3308],\n",
            "        [0.3376],\n",
            "        [0.3443],\n",
            "        [0.3510],\n",
            "        [0.3578],\n",
            "        [0.3645],\n",
            "        [0.3712],\n",
            "        [0.3780],\n",
            "        [0.3847],\n",
            "        [0.3914]], grad_fn=<AddBackward0>)\n",
            "Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.48106518387794495 \n",
            "tensor([[0.1388],\n",
            "        [0.1456],\n",
            "        [0.1524],\n",
            "        [0.1592],\n",
            "        [0.1661],\n",
            "        [0.1729],\n",
            "        [0.1797],\n",
            "        [0.1865],\n",
            "        [0.1933],\n",
            "        [0.2001],\n",
            "        [0.2069],\n",
            "        [0.2137],\n",
            "        [0.2206],\n",
            "        [0.2274],\n",
            "        [0.2342],\n",
            "        [0.2410],\n",
            "        [0.2478],\n",
            "        [0.2546],\n",
            "        [0.2614],\n",
            "        [0.2682],\n",
            "        [0.2750],\n",
            "        [0.2819],\n",
            "        [0.2887],\n",
            "        [0.2955],\n",
            "        [0.3023],\n",
            "        [0.3091],\n",
            "        [0.3159],\n",
            "        [0.3227],\n",
            "        [0.3295],\n",
            "        [0.3364],\n",
            "        [0.3432],\n",
            "        [0.3500],\n",
            "        [0.3568],\n",
            "        [0.3636],\n",
            "        [0.3704],\n",
            "        [0.3772],\n",
            "        [0.3840],\n",
            "        [0.3908],\n",
            "        [0.3977],\n",
            "        [0.4045]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.1488],\n",
            "        [0.1557],\n",
            "        [0.1626],\n",
            "        [0.1695],\n",
            "        [0.1764],\n",
            "        [0.1833],\n",
            "        [0.1901],\n",
            "        [0.1970],\n",
            "        [0.2039],\n",
            "        [0.2108],\n",
            "        [0.2177],\n",
            "        [0.2246],\n",
            "        [0.2315],\n",
            "        [0.2384],\n",
            "        [0.2453],\n",
            "        [0.2522],\n",
            "        [0.2590],\n",
            "        [0.2659],\n",
            "        [0.2728],\n",
            "        [0.2797],\n",
            "        [0.2866],\n",
            "        [0.2935],\n",
            "        [0.3004],\n",
            "        [0.3073],\n",
            "        [0.3142],\n",
            "        [0.3211],\n",
            "        [0.3279],\n",
            "        [0.3348],\n",
            "        [0.3417],\n",
            "        [0.3486],\n",
            "        [0.3555],\n",
            "        [0.3624],\n",
            "        [0.3693],\n",
            "        [0.3762],\n",
            "        [0.3831],\n",
            "        [0.3900],\n",
            "        [0.3968],\n",
            "        [0.4037],\n",
            "        [0.4106],\n",
            "        [0.4175]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.1588],\n",
            "        [0.1658],\n",
            "        [0.1727],\n",
            "        [0.1797],\n",
            "        [0.1867],\n",
            "        [0.1936],\n",
            "        [0.2006],\n",
            "        [0.2076],\n",
            "        [0.2146],\n",
            "        [0.2215],\n",
            "        [0.2285],\n",
            "        [0.2355],\n",
            "        [0.2424],\n",
            "        [0.2494],\n",
            "        [0.2564],\n",
            "        [0.2633],\n",
            "        [0.2703],\n",
            "        [0.2773],\n",
            "        [0.2842],\n",
            "        [0.2912],\n",
            "        [0.2982],\n",
            "        [0.3051],\n",
            "        [0.3121],\n",
            "        [0.3191],\n",
            "        [0.3260],\n",
            "        [0.3330],\n",
            "        [0.3400],\n",
            "        [0.3469],\n",
            "        [0.3539],\n",
            "        [0.3609],\n",
            "        [0.3678],\n",
            "        [0.3748],\n",
            "        [0.3818],\n",
            "        [0.3887],\n",
            "        [0.3957],\n",
            "        [0.4027],\n",
            "        [0.4097],\n",
            "        [0.4166],\n",
            "        [0.4236],\n",
            "        [0.4306]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.1688],\n",
            "        [0.1759],\n",
            "        [0.1829],\n",
            "        [0.1899],\n",
            "        [0.1970],\n",
            "        [0.2040],\n",
            "        [0.2111],\n",
            "        [0.2181],\n",
            "        [0.2252],\n",
            "        [0.2322],\n",
            "        [0.2393],\n",
            "        [0.2463],\n",
            "        [0.2534],\n",
            "        [0.2604],\n",
            "        [0.2675],\n",
            "        [0.2745],\n",
            "        [0.2815],\n",
            "        [0.2886],\n",
            "        [0.2956],\n",
            "        [0.3027],\n",
            "        [0.3097],\n",
            "        [0.3168],\n",
            "        [0.3238],\n",
            "        [0.3309],\n",
            "        [0.3379],\n",
            "        [0.3450],\n",
            "        [0.3520],\n",
            "        [0.3590],\n",
            "        [0.3661],\n",
            "        [0.3731],\n",
            "        [0.3802],\n",
            "        [0.3872],\n",
            "        [0.3943],\n",
            "        [0.4013],\n",
            "        [0.4084],\n",
            "        [0.4154],\n",
            "        [0.4225],\n",
            "        [0.4295],\n",
            "        [0.4366],\n",
            "        [0.4436]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.1788],\n",
            "        [0.1859],\n",
            "        [0.1931],\n",
            "        [0.2002],\n",
            "        [0.2073],\n",
            "        [0.2144],\n",
            "        [0.2216],\n",
            "        [0.2287],\n",
            "        [0.2358],\n",
            "        [0.2429],\n",
            "        [0.2500],\n",
            "        [0.2572],\n",
            "        [0.2643],\n",
            "        [0.2714],\n",
            "        [0.2785],\n",
            "        [0.2857],\n",
            "        [0.2928],\n",
            "        [0.2999],\n",
            "        [0.3070],\n",
            "        [0.3142],\n",
            "        [0.3213],\n",
            "        [0.3284],\n",
            "        [0.3355],\n",
            "        [0.3427],\n",
            "        [0.3498],\n",
            "        [0.3569],\n",
            "        [0.3640],\n",
            "        [0.3712],\n",
            "        [0.3783],\n",
            "        [0.3854],\n",
            "        [0.3925],\n",
            "        [0.3996],\n",
            "        [0.4068],\n",
            "        [0.4139],\n",
            "        [0.4210],\n",
            "        [0.4281],\n",
            "        [0.4353],\n",
            "        [0.4424],\n",
            "        [0.4495],\n",
            "        [0.4566]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.1888],\n",
            "        [0.1960],\n",
            "        [0.2032],\n",
            "        [0.2104],\n",
            "        [0.2176],\n",
            "        [0.2248],\n",
            "        [0.2320],\n",
            "        [0.2392],\n",
            "        [0.2464],\n",
            "        [0.2536],\n",
            "        [0.2608],\n",
            "        [0.2680],\n",
            "        [0.2752],\n",
            "        [0.2824],\n",
            "        [0.2896],\n",
            "        [0.2968],\n",
            "        [0.3040],\n",
            "        [0.3112],\n",
            "        [0.3184],\n",
            "        [0.3256],\n",
            "        [0.3328],\n",
            "        [0.3400],\n",
            "        [0.3472],\n",
            "        [0.3545],\n",
            "        [0.3617],\n",
            "        [0.3689],\n",
            "        [0.3761],\n",
            "        [0.3833],\n",
            "        [0.3905],\n",
            "        [0.3977],\n",
            "        [0.4049],\n",
            "        [0.4121],\n",
            "        [0.4193],\n",
            "        [0.4265],\n",
            "        [0.4337],\n",
            "        [0.4409],\n",
            "        [0.4481],\n",
            "        [0.4553],\n",
            "        [0.4625],\n",
            "        [0.4697]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.1988],\n",
            "        [0.2061],\n",
            "        [0.2134],\n",
            "        [0.2206],\n",
            "        [0.2279],\n",
            "        [0.2352],\n",
            "        [0.2425],\n",
            "        [0.2498],\n",
            "        [0.2570],\n",
            "        [0.2643],\n",
            "        [0.2716],\n",
            "        [0.2789],\n",
            "        [0.2862],\n",
            "        [0.2934],\n",
            "        [0.3007],\n",
            "        [0.3080],\n",
            "        [0.3153],\n",
            "        [0.3226],\n",
            "        [0.3298],\n",
            "        [0.3371],\n",
            "        [0.3444],\n",
            "        [0.3517],\n",
            "        [0.3590],\n",
            "        [0.3662],\n",
            "        [0.3735],\n",
            "        [0.3808],\n",
            "        [0.3881],\n",
            "        [0.3954],\n",
            "        [0.4026],\n",
            "        [0.4099],\n",
            "        [0.4172],\n",
            "        [0.4245],\n",
            "        [0.4318],\n",
            "        [0.4390],\n",
            "        [0.4463],\n",
            "        [0.4536],\n",
            "        [0.4609],\n",
            "        [0.4682],\n",
            "        [0.4754],\n",
            "        [0.4827]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2088],\n",
            "        [0.2162],\n",
            "        [0.2235],\n",
            "        [0.2309],\n",
            "        [0.2382],\n",
            "        [0.2456],\n",
            "        [0.2530],\n",
            "        [0.2603],\n",
            "        [0.2677],\n",
            "        [0.2750],\n",
            "        [0.2824],\n",
            "        [0.2897],\n",
            "        [0.2971],\n",
            "        [0.3045],\n",
            "        [0.3118],\n",
            "        [0.3192],\n",
            "        [0.3265],\n",
            "        [0.3339],\n",
            "        [0.3412],\n",
            "        [0.3486],\n",
            "        [0.3560],\n",
            "        [0.3633],\n",
            "        [0.3707],\n",
            "        [0.3780],\n",
            "        [0.3854],\n",
            "        [0.3928],\n",
            "        [0.4001],\n",
            "        [0.4075],\n",
            "        [0.4148],\n",
            "        [0.4222],\n",
            "        [0.4295],\n",
            "        [0.4369],\n",
            "        [0.4443],\n",
            "        [0.4516],\n",
            "        [0.4590],\n",
            "        [0.4663],\n",
            "        [0.4737],\n",
            "        [0.4810],\n",
            "        [0.4884],\n",
            "        [0.4958]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2188],\n",
            "        [0.2262],\n",
            "        [0.2337],\n",
            "        [0.2411],\n",
            "        [0.2486],\n",
            "        [0.2560],\n",
            "        [0.2634],\n",
            "        [0.2709],\n",
            "        [0.2783],\n",
            "        [0.2857],\n",
            "        [0.2932],\n",
            "        [0.3006],\n",
            "        [0.3080],\n",
            "        [0.3155],\n",
            "        [0.3229],\n",
            "        [0.3303],\n",
            "        [0.3378],\n",
            "        [0.3452],\n",
            "        [0.3527],\n",
            "        [0.3601],\n",
            "        [0.3675],\n",
            "        [0.3750],\n",
            "        [0.3824],\n",
            "        [0.3898],\n",
            "        [0.3973],\n",
            "        [0.4047],\n",
            "        [0.4121],\n",
            "        [0.4196],\n",
            "        [0.4270],\n",
            "        [0.4344],\n",
            "        [0.4419],\n",
            "        [0.4493],\n",
            "        [0.4568],\n",
            "        [0.4642],\n",
            "        [0.4716],\n",
            "        [0.4791],\n",
            "        [0.4865],\n",
            "        [0.4939],\n",
            "        [0.5014],\n",
            "        [0.5088]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2288],\n",
            "        [0.2363],\n",
            "        [0.2438],\n",
            "        [0.2514],\n",
            "        [0.2589],\n",
            "        [0.2664],\n",
            "        [0.2739],\n",
            "        [0.2814],\n",
            "        [0.2889],\n",
            "        [0.2964],\n",
            "        [0.3039],\n",
            "        [0.3115],\n",
            "        [0.3190],\n",
            "        [0.3265],\n",
            "        [0.3340],\n",
            "        [0.3415],\n",
            "        [0.3490],\n",
            "        [0.3565],\n",
            "        [0.3641],\n",
            "        [0.3716],\n",
            "        [0.3791],\n",
            "        [0.3866],\n",
            "        [0.3941],\n",
            "        [0.4016],\n",
            "        [0.4091],\n",
            "        [0.4167],\n",
            "        [0.4242],\n",
            "        [0.4317],\n",
            "        [0.4392],\n",
            "        [0.4467],\n",
            "        [0.4542],\n",
            "        [0.4617],\n",
            "        [0.4693],\n",
            "        [0.4768],\n",
            "        [0.4843],\n",
            "        [0.4918],\n",
            "        [0.4993],\n",
            "        [0.5068],\n",
            "        [0.5143],\n",
            "        [0.5218]], grad_fn=<AddBackward0>)\n",
            "Epoch: 10 | MAE Train Loss: 0.1976713240146637 | MAE Test Loss: 0.3463551998138428 \n",
            "tensor([[0.2388],\n",
            "        [0.2464],\n",
            "        [0.2540],\n",
            "        [0.2616],\n",
            "        [0.2692],\n",
            "        [0.2768],\n",
            "        [0.2844],\n",
            "        [0.2920],\n",
            "        [0.2995],\n",
            "        [0.3071],\n",
            "        [0.3147],\n",
            "        [0.3223],\n",
            "        [0.3299],\n",
            "        [0.3375],\n",
            "        [0.3451],\n",
            "        [0.3527],\n",
            "        [0.3603],\n",
            "        [0.3679],\n",
            "        [0.3755],\n",
            "        [0.3831],\n",
            "        [0.3906],\n",
            "        [0.3982],\n",
            "        [0.4058],\n",
            "        [0.4134],\n",
            "        [0.4210],\n",
            "        [0.4286],\n",
            "        [0.4362],\n",
            "        [0.4438],\n",
            "        [0.4514],\n",
            "        [0.4590],\n",
            "        [0.4666],\n",
            "        [0.4742],\n",
            "        [0.4817],\n",
            "        [0.4893],\n",
            "        [0.4969],\n",
            "        [0.5045],\n",
            "        [0.5121],\n",
            "        [0.5197],\n",
            "        [0.5273],\n",
            "        [0.5349]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2488],\n",
            "        [0.2565],\n",
            "        [0.2641],\n",
            "        [0.2718],\n",
            "        [0.2795],\n",
            "        [0.2872],\n",
            "        [0.2948],\n",
            "        [0.3025],\n",
            "        [0.3102],\n",
            "        [0.3178],\n",
            "        [0.3255],\n",
            "        [0.3332],\n",
            "        [0.3408],\n",
            "        [0.3485],\n",
            "        [0.3562],\n",
            "        [0.3639],\n",
            "        [0.3715],\n",
            "        [0.3792],\n",
            "        [0.3869],\n",
            "        [0.3945],\n",
            "        [0.4022],\n",
            "        [0.4099],\n",
            "        [0.4175],\n",
            "        [0.4252],\n",
            "        [0.4329],\n",
            "        [0.4406],\n",
            "        [0.4482],\n",
            "        [0.4559],\n",
            "        [0.4636],\n",
            "        [0.4712],\n",
            "        [0.4789],\n",
            "        [0.4866],\n",
            "        [0.4942],\n",
            "        [0.5019],\n",
            "        [0.5096],\n",
            "        [0.5173],\n",
            "        [0.5249],\n",
            "        [0.5326],\n",
            "        [0.5403],\n",
            "        [0.5479]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2588],\n",
            "        [0.2666],\n",
            "        [0.2743],\n",
            "        [0.2821],\n",
            "        [0.2898],\n",
            "        [0.2975],\n",
            "        [0.3053],\n",
            "        [0.3130],\n",
            "        [0.3208],\n",
            "        [0.3285],\n",
            "        [0.3363],\n",
            "        [0.3440],\n",
            "        [0.3518],\n",
            "        [0.3595],\n",
            "        [0.3673],\n",
            "        [0.3750],\n",
            "        [0.3828],\n",
            "        [0.3905],\n",
            "        [0.3983],\n",
            "        [0.4060],\n",
            "        [0.4138],\n",
            "        [0.4215],\n",
            "        [0.4293],\n",
            "        [0.4370],\n",
            "        [0.4448],\n",
            "        [0.4525],\n",
            "        [0.4603],\n",
            "        [0.4680],\n",
            "        [0.4757],\n",
            "        [0.4835],\n",
            "        [0.4912],\n",
            "        [0.4990],\n",
            "        [0.5067],\n",
            "        [0.5145],\n",
            "        [0.5222],\n",
            "        [0.5300],\n",
            "        [0.5377],\n",
            "        [0.5455],\n",
            "        [0.5532],\n",
            "        [0.5610]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2688],\n",
            "        [0.2766],\n",
            "        [0.2845],\n",
            "        [0.2923],\n",
            "        [0.3001],\n",
            "        [0.3079],\n",
            "        [0.3158],\n",
            "        [0.3236],\n",
            "        [0.3314],\n",
            "        [0.3392],\n",
            "        [0.3471],\n",
            "        [0.3549],\n",
            "        [0.3627],\n",
            "        [0.3705],\n",
            "        [0.3784],\n",
            "        [0.3862],\n",
            "        [0.3940],\n",
            "        [0.4018],\n",
            "        [0.4097],\n",
            "        [0.4175],\n",
            "        [0.4253],\n",
            "        [0.4332],\n",
            "        [0.4410],\n",
            "        [0.4488],\n",
            "        [0.4566],\n",
            "        [0.4645],\n",
            "        [0.4723],\n",
            "        [0.4801],\n",
            "        [0.4879],\n",
            "        [0.4958],\n",
            "        [0.5036],\n",
            "        [0.5114],\n",
            "        [0.5192],\n",
            "        [0.5271],\n",
            "        [0.5349],\n",
            "        [0.5427],\n",
            "        [0.5505],\n",
            "        [0.5584],\n",
            "        [0.5662],\n",
            "        [0.5740]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2788],\n",
            "        [0.2867],\n",
            "        [0.2946],\n",
            "        [0.3025],\n",
            "        [0.3104],\n",
            "        [0.3183],\n",
            "        [0.3262],\n",
            "        [0.3341],\n",
            "        [0.3420],\n",
            "        [0.3499],\n",
            "        [0.3578],\n",
            "        [0.3658],\n",
            "        [0.3737],\n",
            "        [0.3816],\n",
            "        [0.3895],\n",
            "        [0.3974],\n",
            "        [0.4053],\n",
            "        [0.4132],\n",
            "        [0.4211],\n",
            "        [0.4290],\n",
            "        [0.4369],\n",
            "        [0.4448],\n",
            "        [0.4527],\n",
            "        [0.4606],\n",
            "        [0.4685],\n",
            "        [0.4764],\n",
            "        [0.4843],\n",
            "        [0.4922],\n",
            "        [0.5001],\n",
            "        [0.5080],\n",
            "        [0.5159],\n",
            "        [0.5238],\n",
            "        [0.5317],\n",
            "        [0.5396],\n",
            "        [0.5475],\n",
            "        [0.5554],\n",
            "        [0.5633],\n",
            "        [0.5713],\n",
            "        [0.5792],\n",
            "        [0.5871]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2888],\n",
            "        [0.2968],\n",
            "        [0.3048],\n",
            "        [0.3128],\n",
            "        [0.3207],\n",
            "        [0.3287],\n",
            "        [0.3367],\n",
            "        [0.3447],\n",
            "        [0.3527],\n",
            "        [0.3606],\n",
            "        [0.3686],\n",
            "        [0.3766],\n",
            "        [0.3846],\n",
            "        [0.3926],\n",
            "        [0.4006],\n",
            "        [0.4085],\n",
            "        [0.4165],\n",
            "        [0.4245],\n",
            "        [0.4325],\n",
            "        [0.4405],\n",
            "        [0.4484],\n",
            "        [0.4564],\n",
            "        [0.4644],\n",
            "        [0.4724],\n",
            "        [0.4804],\n",
            "        [0.4884],\n",
            "        [0.4963],\n",
            "        [0.5043],\n",
            "        [0.5123],\n",
            "        [0.5203],\n",
            "        [0.5283],\n",
            "        [0.5362],\n",
            "        [0.5442],\n",
            "        [0.5522],\n",
            "        [0.5602],\n",
            "        [0.5682],\n",
            "        [0.5762],\n",
            "        [0.5841],\n",
            "        [0.5921],\n",
            "        [0.6001]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2988],\n",
            "        [0.3069],\n",
            "        [0.3149],\n",
            "        [0.3230],\n",
            "        [0.3310],\n",
            "        [0.3391],\n",
            "        [0.3472],\n",
            "        [0.3552],\n",
            "        [0.3633],\n",
            "        [0.3713],\n",
            "        [0.3794],\n",
            "        [0.3875],\n",
            "        [0.3955],\n",
            "        [0.4036],\n",
            "        [0.4116],\n",
            "        [0.4197],\n",
            "        [0.4278],\n",
            "        [0.4358],\n",
            "        [0.4439],\n",
            "        [0.4519],\n",
            "        [0.4600],\n",
            "        [0.4681],\n",
            "        [0.4761],\n",
            "        [0.4842],\n",
            "        [0.4922],\n",
            "        [0.5003],\n",
            "        [0.5084],\n",
            "        [0.5164],\n",
            "        [0.5245],\n",
            "        [0.5325],\n",
            "        [0.5406],\n",
            "        [0.5487],\n",
            "        [0.5567],\n",
            "        [0.5648],\n",
            "        [0.5728],\n",
            "        [0.5809],\n",
            "        [0.5890],\n",
            "        [0.5970],\n",
            "        [0.6051],\n",
            "        [0.6131]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3088],\n",
            "        [0.3169],\n",
            "        [0.3251],\n",
            "        [0.3332],\n",
            "        [0.3414],\n",
            "        [0.3495],\n",
            "        [0.3576],\n",
            "        [0.3658],\n",
            "        [0.3739],\n",
            "        [0.3820],\n",
            "        [0.3902],\n",
            "        [0.3983],\n",
            "        [0.4065],\n",
            "        [0.4146],\n",
            "        [0.4227],\n",
            "        [0.4309],\n",
            "        [0.4390],\n",
            "        [0.4472],\n",
            "        [0.4553],\n",
            "        [0.4634],\n",
            "        [0.4716],\n",
            "        [0.4797],\n",
            "        [0.4878],\n",
            "        [0.4960],\n",
            "        [0.5041],\n",
            "        [0.5123],\n",
            "        [0.5204],\n",
            "        [0.5285],\n",
            "        [0.5367],\n",
            "        [0.5448],\n",
            "        [0.5529],\n",
            "        [0.5611],\n",
            "        [0.5692],\n",
            "        [0.5774],\n",
            "        [0.5855],\n",
            "        [0.5936],\n",
            "        [0.6018],\n",
            "        [0.6099],\n",
            "        [0.6180],\n",
            "        [0.6262]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3178],\n",
            "        [0.3260],\n",
            "        [0.3342],\n",
            "        [0.3425],\n",
            "        [0.3507],\n",
            "        [0.3589],\n",
            "        [0.3671],\n",
            "        [0.3753],\n",
            "        [0.3835],\n",
            "        [0.3917],\n",
            "        [0.4000],\n",
            "        [0.4082],\n",
            "        [0.4164],\n",
            "        [0.4246],\n",
            "        [0.4328],\n",
            "        [0.4410],\n",
            "        [0.4493],\n",
            "        [0.4575],\n",
            "        [0.4657],\n",
            "        [0.4739],\n",
            "        [0.4821],\n",
            "        [0.4903],\n",
            "        [0.4986],\n",
            "        [0.5068],\n",
            "        [0.5150],\n",
            "        [0.5232],\n",
            "        [0.5314],\n",
            "        [0.5396],\n",
            "        [0.5478],\n",
            "        [0.5561],\n",
            "        [0.5643],\n",
            "        [0.5725],\n",
            "        [0.5807],\n",
            "        [0.5889],\n",
            "        [0.5971],\n",
            "        [0.6054],\n",
            "        [0.6136],\n",
            "        [0.6218],\n",
            "        [0.6300],\n",
            "        [0.6382]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3258],\n",
            "        [0.3341],\n",
            "        [0.3424],\n",
            "        [0.3507],\n",
            "        [0.3590],\n",
            "        [0.3673],\n",
            "        [0.3756],\n",
            "        [0.3839],\n",
            "        [0.3921],\n",
            "        [0.4004],\n",
            "        [0.4087],\n",
            "        [0.4170],\n",
            "        [0.4253],\n",
            "        [0.4336],\n",
            "        [0.4419],\n",
            "        [0.4502],\n",
            "        [0.4585],\n",
            "        [0.4668],\n",
            "        [0.4751],\n",
            "        [0.4834],\n",
            "        [0.4917],\n",
            "        [0.4999],\n",
            "        [0.5082],\n",
            "        [0.5165],\n",
            "        [0.5248],\n",
            "        [0.5331],\n",
            "        [0.5414],\n",
            "        [0.5497],\n",
            "        [0.5580],\n",
            "        [0.5663],\n",
            "        [0.5746],\n",
            "        [0.5829],\n",
            "        [0.5912],\n",
            "        [0.5995],\n",
            "        [0.6078],\n",
            "        [0.6160],\n",
            "        [0.6243],\n",
            "        [0.6326],\n",
            "        [0.6409],\n",
            "        [0.6492]], grad_fn=<AddBackward0>)\n",
            "Epoch: 20 | MAE Train Loss: 0.08908725529909134 | MAE Test Loss: 0.21729660034179688 \n",
            "tensor([[0.3333],\n",
            "        [0.3417],\n",
            "        [0.3500],\n",
            "        [0.3584],\n",
            "        [0.3668],\n",
            "        [0.3752],\n",
            "        [0.3835],\n",
            "        [0.3919],\n",
            "        [0.4003],\n",
            "        [0.4086],\n",
            "        [0.4170],\n",
            "        [0.4254],\n",
            "        [0.4337],\n",
            "        [0.4421],\n",
            "        [0.4505],\n",
            "        [0.4588],\n",
            "        [0.4672],\n",
            "        [0.4756],\n",
            "        [0.4839],\n",
            "        [0.4923],\n",
            "        [0.5007],\n",
            "        [0.5090],\n",
            "        [0.5174],\n",
            "        [0.5258],\n",
            "        [0.5342],\n",
            "        [0.5425],\n",
            "        [0.5509],\n",
            "        [0.5593],\n",
            "        [0.5676],\n",
            "        [0.5760],\n",
            "        [0.5844],\n",
            "        [0.5927],\n",
            "        [0.6011],\n",
            "        [0.6095],\n",
            "        [0.6178],\n",
            "        [0.6262],\n",
            "        [0.6346],\n",
            "        [0.6429],\n",
            "        [0.6513],\n",
            "        [0.6597]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3403],\n",
            "        [0.3488],\n",
            "        [0.3572],\n",
            "        [0.3656],\n",
            "        [0.3741],\n",
            "        [0.3825],\n",
            "        [0.3910],\n",
            "        [0.3994],\n",
            "        [0.4079],\n",
            "        [0.4163],\n",
            "        [0.4247],\n",
            "        [0.4332],\n",
            "        [0.4416],\n",
            "        [0.4501],\n",
            "        [0.4585],\n",
            "        [0.4670],\n",
            "        [0.4754],\n",
            "        [0.4838],\n",
            "        [0.4923],\n",
            "        [0.5007],\n",
            "        [0.5092],\n",
            "        [0.5176],\n",
            "        [0.5261],\n",
            "        [0.5345],\n",
            "        [0.5430],\n",
            "        [0.5514],\n",
            "        [0.5598],\n",
            "        [0.5683],\n",
            "        [0.5767],\n",
            "        [0.5852],\n",
            "        [0.5936],\n",
            "        [0.6021],\n",
            "        [0.6105],\n",
            "        [0.6189],\n",
            "        [0.6274],\n",
            "        [0.6358],\n",
            "        [0.6443],\n",
            "        [0.6527],\n",
            "        [0.6612],\n",
            "        [0.6696]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3463],\n",
            "        [0.3548],\n",
            "        [0.3633],\n",
            "        [0.3719],\n",
            "        [0.3804],\n",
            "        [0.3889],\n",
            "        [0.3974],\n",
            "        [0.4059],\n",
            "        [0.4144],\n",
            "        [0.4230],\n",
            "        [0.4315],\n",
            "        [0.4400],\n",
            "        [0.4485],\n",
            "        [0.4570],\n",
            "        [0.4655],\n",
            "        [0.4740],\n",
            "        [0.4826],\n",
            "        [0.4911],\n",
            "        [0.4996],\n",
            "        [0.5081],\n",
            "        [0.5166],\n",
            "        [0.5251],\n",
            "        [0.5337],\n",
            "        [0.5422],\n",
            "        [0.5507],\n",
            "        [0.5592],\n",
            "        [0.5677],\n",
            "        [0.5762],\n",
            "        [0.5848],\n",
            "        [0.5933],\n",
            "        [0.6018],\n",
            "        [0.6103],\n",
            "        [0.6188],\n",
            "        [0.6273],\n",
            "        [0.6358],\n",
            "        [0.6444],\n",
            "        [0.6529],\n",
            "        [0.6614],\n",
            "        [0.6699],\n",
            "        [0.6784]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3518],\n",
            "        [0.3604],\n",
            "        [0.3690],\n",
            "        [0.3776],\n",
            "        [0.3862],\n",
            "        [0.3947],\n",
            "        [0.4033],\n",
            "        [0.4119],\n",
            "        [0.4205],\n",
            "        [0.4291],\n",
            "        [0.4377],\n",
            "        [0.4463],\n",
            "        [0.4548],\n",
            "        [0.4634],\n",
            "        [0.4720],\n",
            "        [0.4806],\n",
            "        [0.4892],\n",
            "        [0.4978],\n",
            "        [0.5064],\n",
            "        [0.5150],\n",
            "        [0.5235],\n",
            "        [0.5321],\n",
            "        [0.5407],\n",
            "        [0.5493],\n",
            "        [0.5579],\n",
            "        [0.5665],\n",
            "        [0.5751],\n",
            "        [0.5836],\n",
            "        [0.5922],\n",
            "        [0.6008],\n",
            "        [0.6094],\n",
            "        [0.6180],\n",
            "        [0.6266],\n",
            "        [0.6352],\n",
            "        [0.6438],\n",
            "        [0.6523],\n",
            "        [0.6609],\n",
            "        [0.6695],\n",
            "        [0.6781],\n",
            "        [0.6867]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3568],\n",
            "        [0.3655],\n",
            "        [0.3741],\n",
            "        [0.3828],\n",
            "        [0.3914],\n",
            "        [0.4001],\n",
            "        [0.4087],\n",
            "        [0.4174],\n",
            "        [0.4261],\n",
            "        [0.4347],\n",
            "        [0.4434],\n",
            "        [0.4520],\n",
            "        [0.4607],\n",
            "        [0.4693],\n",
            "        [0.4780],\n",
            "        [0.4866],\n",
            "        [0.4953],\n",
            "        [0.5040],\n",
            "        [0.5126],\n",
            "        [0.5213],\n",
            "        [0.5299],\n",
            "        [0.5386],\n",
            "        [0.5472],\n",
            "        [0.5559],\n",
            "        [0.5645],\n",
            "        [0.5732],\n",
            "        [0.5819],\n",
            "        [0.5905],\n",
            "        [0.5992],\n",
            "        [0.6078],\n",
            "        [0.6165],\n",
            "        [0.6251],\n",
            "        [0.6338],\n",
            "        [0.6424],\n",
            "        [0.6511],\n",
            "        [0.6598],\n",
            "        [0.6684],\n",
            "        [0.6771],\n",
            "        [0.6857],\n",
            "        [0.6944]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3613],\n",
            "        [0.3700],\n",
            "        [0.3788],\n",
            "        [0.3875],\n",
            "        [0.3962],\n",
            "        [0.4049],\n",
            "        [0.4136],\n",
            "        [0.4224],\n",
            "        [0.4311],\n",
            "        [0.4398],\n",
            "        [0.4485],\n",
            "        [0.4573],\n",
            "        [0.4660],\n",
            "        [0.4747],\n",
            "        [0.4834],\n",
            "        [0.4921],\n",
            "        [0.5009],\n",
            "        [0.5096],\n",
            "        [0.5183],\n",
            "        [0.5270],\n",
            "        [0.5358],\n",
            "        [0.5445],\n",
            "        [0.5532],\n",
            "        [0.5619],\n",
            "        [0.5707],\n",
            "        [0.5794],\n",
            "        [0.5881],\n",
            "        [0.5968],\n",
            "        [0.6055],\n",
            "        [0.6143],\n",
            "        [0.6230],\n",
            "        [0.6317],\n",
            "        [0.6404],\n",
            "        [0.6492],\n",
            "        [0.6579],\n",
            "        [0.6666],\n",
            "        [0.6753],\n",
            "        [0.6840],\n",
            "        [0.6928],\n",
            "        [0.7015]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3653],\n",
            "        [0.3741],\n",
            "        [0.3829],\n",
            "        [0.3917],\n",
            "        [0.4005],\n",
            "        [0.4092],\n",
            "        [0.4180],\n",
            "        [0.4268],\n",
            "        [0.4356],\n",
            "        [0.4444],\n",
            "        [0.4532],\n",
            "        [0.4620],\n",
            "        [0.4708],\n",
            "        [0.4795],\n",
            "        [0.4883],\n",
            "        [0.4971],\n",
            "        [0.5059],\n",
            "        [0.5147],\n",
            "        [0.5235],\n",
            "        [0.5323],\n",
            "        [0.5411],\n",
            "        [0.5498],\n",
            "        [0.5586],\n",
            "        [0.5674],\n",
            "        [0.5762],\n",
            "        [0.5850],\n",
            "        [0.5938],\n",
            "        [0.6026],\n",
            "        [0.6114],\n",
            "        [0.6201],\n",
            "        [0.6289],\n",
            "        [0.6377],\n",
            "        [0.6465],\n",
            "        [0.6553],\n",
            "        [0.6641],\n",
            "        [0.6729],\n",
            "        [0.6817],\n",
            "        [0.6904],\n",
            "        [0.6992],\n",
            "        [0.7080]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3688],\n",
            "        [0.3777],\n",
            "        [0.3865],\n",
            "        [0.3954],\n",
            "        [0.4042],\n",
            "        [0.4131],\n",
            "        [0.4219],\n",
            "        [0.4308],\n",
            "        [0.4396],\n",
            "        [0.4485],\n",
            "        [0.4573],\n",
            "        [0.4662],\n",
            "        [0.4750],\n",
            "        [0.4839],\n",
            "        [0.4927],\n",
            "        [0.5016],\n",
            "        [0.5104],\n",
            "        [0.5193],\n",
            "        [0.5281],\n",
            "        [0.5370],\n",
            "        [0.5458],\n",
            "        [0.5547],\n",
            "        [0.5635],\n",
            "        [0.5724],\n",
            "        [0.5812],\n",
            "        [0.5901],\n",
            "        [0.5989],\n",
            "        [0.6078],\n",
            "        [0.6166],\n",
            "        [0.6255],\n",
            "        [0.6343],\n",
            "        [0.6432],\n",
            "        [0.6520],\n",
            "        [0.6609],\n",
            "        [0.6697],\n",
            "        [0.6786],\n",
            "        [0.6874],\n",
            "        [0.6963],\n",
            "        [0.7051],\n",
            "        [0.7140]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3718],\n",
            "        [0.3807],\n",
            "        [0.3896],\n",
            "        [0.3985],\n",
            "        [0.4074],\n",
            "        [0.4164],\n",
            "        [0.4253],\n",
            "        [0.4342],\n",
            "        [0.4431],\n",
            "        [0.4520],\n",
            "        [0.4609],\n",
            "        [0.4698],\n",
            "        [0.4787],\n",
            "        [0.4876],\n",
            "        [0.4965],\n",
            "        [0.5055],\n",
            "        [0.5144],\n",
            "        [0.5233],\n",
            "        [0.5322],\n",
            "        [0.5411],\n",
            "        [0.5500],\n",
            "        [0.5589],\n",
            "        [0.5678],\n",
            "        [0.5767],\n",
            "        [0.5856],\n",
            "        [0.5945],\n",
            "        [0.6035],\n",
            "        [0.6124],\n",
            "        [0.6213],\n",
            "        [0.6302],\n",
            "        [0.6391],\n",
            "        [0.6480],\n",
            "        [0.6569],\n",
            "        [0.6658],\n",
            "        [0.6747],\n",
            "        [0.6836],\n",
            "        [0.6926],\n",
            "        [0.7015],\n",
            "        [0.7104],\n",
            "        [0.7193]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3743],\n",
            "        [0.3833],\n",
            "        [0.3922],\n",
            "        [0.4012],\n",
            "        [0.4102],\n",
            "        [0.4191],\n",
            "        [0.4281],\n",
            "        [0.4371],\n",
            "        [0.4460],\n",
            "        [0.4550],\n",
            "        [0.4640],\n",
            "        [0.4729],\n",
            "        [0.4819],\n",
            "        [0.4909],\n",
            "        [0.4998],\n",
            "        [0.5088],\n",
            "        [0.5178],\n",
            "        [0.5267],\n",
            "        [0.5357],\n",
            "        [0.5447],\n",
            "        [0.5536],\n",
            "        [0.5626],\n",
            "        [0.5716],\n",
            "        [0.5805],\n",
            "        [0.5895],\n",
            "        [0.5985],\n",
            "        [0.6074],\n",
            "        [0.6164],\n",
            "        [0.6254],\n",
            "        [0.6343],\n",
            "        [0.6433],\n",
            "        [0.6523],\n",
            "        [0.6612],\n",
            "        [0.6702],\n",
            "        [0.6792],\n",
            "        [0.6881],\n",
            "        [0.6971],\n",
            "        [0.7061],\n",
            "        [0.7150],\n",
            "        [0.7240]], grad_fn=<AddBackward0>)\n",
            "Epoch: 30 | MAE Train Loss: 0.053148526698350906 | MAE Test Loss: 0.14464017748832703 \n",
            "tensor([[0.3768],\n",
            "        [0.3858],\n",
            "        [0.3949],\n",
            "        [0.4039],\n",
            "        [0.4129],\n",
            "        [0.4219],\n",
            "        [0.4310],\n",
            "        [0.4400],\n",
            "        [0.4490],\n",
            "        [0.4580],\n",
            "        [0.4670],\n",
            "        [0.4761],\n",
            "        [0.4851],\n",
            "        [0.4941],\n",
            "        [0.5031],\n",
            "        [0.5122],\n",
            "        [0.5212],\n",
            "        [0.5302],\n",
            "        [0.5392],\n",
            "        [0.5483],\n",
            "        [0.5573],\n",
            "        [0.5663],\n",
            "        [0.5753],\n",
            "        [0.5844],\n",
            "        [0.5934],\n",
            "        [0.6024],\n",
            "        [0.6114],\n",
            "        [0.6204],\n",
            "        [0.6295],\n",
            "        [0.6385],\n",
            "        [0.6475],\n",
            "        [0.6565],\n",
            "        [0.6656],\n",
            "        [0.6746],\n",
            "        [0.6836],\n",
            "        [0.6926],\n",
            "        [0.7017],\n",
            "        [0.7107],\n",
            "        [0.7197],\n",
            "        [0.7287]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3788],\n",
            "        [0.3879],\n",
            "        [0.3970],\n",
            "        [0.4060],\n",
            "        [0.4151],\n",
            "        [0.4242],\n",
            "        [0.4333],\n",
            "        [0.4424],\n",
            "        [0.4514],\n",
            "        [0.4605],\n",
            "        [0.4696],\n",
            "        [0.4787],\n",
            "        [0.4877],\n",
            "        [0.4968],\n",
            "        [0.5059],\n",
            "        [0.5150],\n",
            "        [0.5241],\n",
            "        [0.5331],\n",
            "        [0.5422],\n",
            "        [0.5513],\n",
            "        [0.5604],\n",
            "        [0.5694],\n",
            "        [0.5785],\n",
            "        [0.5876],\n",
            "        [0.5967],\n",
            "        [0.6057],\n",
            "        [0.6148],\n",
            "        [0.6239],\n",
            "        [0.6330],\n",
            "        [0.6421],\n",
            "        [0.6511],\n",
            "        [0.6602],\n",
            "        [0.6693],\n",
            "        [0.6784],\n",
            "        [0.6874],\n",
            "        [0.6965],\n",
            "        [0.7056],\n",
            "        [0.7147],\n",
            "        [0.7238],\n",
            "        [0.7328]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3803],\n",
            "        [0.3894],\n",
            "        [0.3986],\n",
            "        [0.4077],\n",
            "        [0.4168],\n",
            "        [0.4260],\n",
            "        [0.4351],\n",
            "        [0.4442],\n",
            "        [0.4533],\n",
            "        [0.4625],\n",
            "        [0.4716],\n",
            "        [0.4807],\n",
            "        [0.4899],\n",
            "        [0.4990],\n",
            "        [0.5081],\n",
            "        [0.5172],\n",
            "        [0.5264],\n",
            "        [0.5355],\n",
            "        [0.5446],\n",
            "        [0.5537],\n",
            "        [0.5629],\n",
            "        [0.5720],\n",
            "        [0.5811],\n",
            "        [0.5903],\n",
            "        [0.5994],\n",
            "        [0.6085],\n",
            "        [0.6176],\n",
            "        [0.6268],\n",
            "        [0.6359],\n",
            "        [0.6450],\n",
            "        [0.6542],\n",
            "        [0.6633],\n",
            "        [0.6724],\n",
            "        [0.6815],\n",
            "        [0.6907],\n",
            "        [0.6998],\n",
            "        [0.7089],\n",
            "        [0.7181],\n",
            "        [0.7272],\n",
            "        [0.7363]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3818],\n",
            "        [0.3910],\n",
            "        [0.4002],\n",
            "        [0.4093],\n",
            "        [0.4185],\n",
            "        [0.4277],\n",
            "        [0.4369],\n",
            "        [0.4461],\n",
            "        [0.4552],\n",
            "        [0.4644],\n",
            "        [0.4736],\n",
            "        [0.4828],\n",
            "        [0.4920],\n",
            "        [0.5011],\n",
            "        [0.5103],\n",
            "        [0.5195],\n",
            "        [0.5287],\n",
            "        [0.5379],\n",
            "        [0.5470],\n",
            "        [0.5562],\n",
            "        [0.5654],\n",
            "        [0.5746],\n",
            "        [0.5838],\n",
            "        [0.5929],\n",
            "        [0.6021],\n",
            "        [0.6113],\n",
            "        [0.6205],\n",
            "        [0.6296],\n",
            "        [0.6388],\n",
            "        [0.6480],\n",
            "        [0.6572],\n",
            "        [0.6664],\n",
            "        [0.6755],\n",
            "        [0.6847],\n",
            "        [0.6939],\n",
            "        [0.7031],\n",
            "        [0.7123],\n",
            "        [0.7214],\n",
            "        [0.7306],\n",
            "        [0.7398]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3833],\n",
            "        [0.3925],\n",
            "        [0.4018],\n",
            "        [0.4110],\n",
            "        [0.4202],\n",
            "        [0.4295],\n",
            "        [0.4387],\n",
            "        [0.4479],\n",
            "        [0.4571],\n",
            "        [0.4664],\n",
            "        [0.4756],\n",
            "        [0.4848],\n",
            "        [0.4941],\n",
            "        [0.5033],\n",
            "        [0.5125],\n",
            "        [0.5218],\n",
            "        [0.5310],\n",
            "        [0.5402],\n",
            "        [0.5494],\n",
            "        [0.5587],\n",
            "        [0.5679],\n",
            "        [0.5771],\n",
            "        [0.5864],\n",
            "        [0.5956],\n",
            "        [0.6048],\n",
            "        [0.6141],\n",
            "        [0.6233],\n",
            "        [0.6325],\n",
            "        [0.6417],\n",
            "        [0.6510],\n",
            "        [0.6602],\n",
            "        [0.6694],\n",
            "        [0.6787],\n",
            "        [0.6879],\n",
            "        [0.6971],\n",
            "        [0.7064],\n",
            "        [0.7156],\n",
            "        [0.7248],\n",
            "        [0.7340],\n",
            "        [0.7433]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3843],\n",
            "        [0.3936],\n",
            "        [0.4029],\n",
            "        [0.4121],\n",
            "        [0.4214],\n",
            "        [0.4307],\n",
            "        [0.4400],\n",
            "        [0.4493],\n",
            "        [0.4585],\n",
            "        [0.4678],\n",
            "        [0.4771],\n",
            "        [0.4864],\n",
            "        [0.4956],\n",
            "        [0.5049],\n",
            "        [0.5142],\n",
            "        [0.5235],\n",
            "        [0.5327],\n",
            "        [0.5420],\n",
            "        [0.5513],\n",
            "        [0.5606],\n",
            "        [0.5699],\n",
            "        [0.5791],\n",
            "        [0.5884],\n",
            "        [0.5977],\n",
            "        [0.6070],\n",
            "        [0.6162],\n",
            "        [0.6255],\n",
            "        [0.6348],\n",
            "        [0.6441],\n",
            "        [0.6534],\n",
            "        [0.6626],\n",
            "        [0.6719],\n",
            "        [0.6812],\n",
            "        [0.6905],\n",
            "        [0.6997],\n",
            "        [0.7090],\n",
            "        [0.7183],\n",
            "        [0.7276],\n",
            "        [0.7369],\n",
            "        [0.7461]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3853],\n",
            "        [0.3946],\n",
            "        [0.4040],\n",
            "        [0.4133],\n",
            "        [0.4226],\n",
            "        [0.4319],\n",
            "        [0.4413],\n",
            "        [0.4506],\n",
            "        [0.4599],\n",
            "        [0.4692],\n",
            "        [0.4786],\n",
            "        [0.4879],\n",
            "        [0.4972],\n",
            "        [0.5065],\n",
            "        [0.5159],\n",
            "        [0.5252],\n",
            "        [0.5345],\n",
            "        [0.5438],\n",
            "        [0.5532],\n",
            "        [0.5625],\n",
            "        [0.5718],\n",
            "        [0.5811],\n",
            "        [0.5905],\n",
            "        [0.5998],\n",
            "        [0.6091],\n",
            "        [0.6184],\n",
            "        [0.6278],\n",
            "        [0.6371],\n",
            "        [0.6464],\n",
            "        [0.6557],\n",
            "        [0.6651],\n",
            "        [0.6744],\n",
            "        [0.6837],\n",
            "        [0.6930],\n",
            "        [0.7024],\n",
            "        [0.7117],\n",
            "        [0.7210],\n",
            "        [0.7303],\n",
            "        [0.7397],\n",
            "        [0.7490]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3858],\n",
            "        [0.3952],\n",
            "        [0.4045],\n",
            "        [0.4139],\n",
            "        [0.4233],\n",
            "        [0.4327],\n",
            "        [0.4420],\n",
            "        [0.4514],\n",
            "        [0.4608],\n",
            "        [0.4701],\n",
            "        [0.4795],\n",
            "        [0.4889],\n",
            "        [0.4982],\n",
            "        [0.5076],\n",
            "        [0.5170],\n",
            "        [0.5263],\n",
            "        [0.5357],\n",
            "        [0.5451],\n",
            "        [0.5544],\n",
            "        [0.5638],\n",
            "        [0.5732],\n",
            "        [0.5826],\n",
            "        [0.5919],\n",
            "        [0.6013],\n",
            "        [0.6107],\n",
            "        [0.6200],\n",
            "        [0.6294],\n",
            "        [0.6388],\n",
            "        [0.6481],\n",
            "        [0.6575],\n",
            "        [0.6669],\n",
            "        [0.6762],\n",
            "        [0.6856],\n",
            "        [0.6950],\n",
            "        [0.7043],\n",
            "        [0.7137],\n",
            "        [0.7231],\n",
            "        [0.7324],\n",
            "        [0.7418],\n",
            "        [0.7512]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3863],\n",
            "        [0.3957],\n",
            "        [0.4051],\n",
            "        [0.4145],\n",
            "        [0.4240],\n",
            "        [0.4334],\n",
            "        [0.4428],\n",
            "        [0.4522],\n",
            "        [0.4616],\n",
            "        [0.4710],\n",
            "        [0.4804],\n",
            "        [0.4898],\n",
            "        [0.4993],\n",
            "        [0.5087],\n",
            "        [0.5181],\n",
            "        [0.5275],\n",
            "        [0.5369],\n",
            "        [0.5463],\n",
            "        [0.5557],\n",
            "        [0.5651],\n",
            "        [0.5746],\n",
            "        [0.5840],\n",
            "        [0.5934],\n",
            "        [0.6028],\n",
            "        [0.6122],\n",
            "        [0.6216],\n",
            "        [0.6310],\n",
            "        [0.6404],\n",
            "        [0.6499],\n",
            "        [0.6593],\n",
            "        [0.6687],\n",
            "        [0.6781],\n",
            "        [0.6875],\n",
            "        [0.6969],\n",
            "        [0.7063],\n",
            "        [0.7157],\n",
            "        [0.7252],\n",
            "        [0.7346],\n",
            "        [0.7440],\n",
            "        [0.7534]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3868],\n",
            "        [0.3963],\n",
            "        [0.4057],\n",
            "        [0.4152],\n",
            "        [0.4246],\n",
            "        [0.4341],\n",
            "        [0.4435],\n",
            "        [0.4530],\n",
            "        [0.4625],\n",
            "        [0.4719],\n",
            "        [0.4814],\n",
            "        [0.4908],\n",
            "        [0.5003],\n",
            "        [0.5097],\n",
            "        [0.5192],\n",
            "        [0.5287],\n",
            "        [0.5381],\n",
            "        [0.5476],\n",
            "        [0.5570],\n",
            "        [0.5665],\n",
            "        [0.5759],\n",
            "        [0.5854],\n",
            "        [0.5948],\n",
            "        [0.6043],\n",
            "        [0.6138],\n",
            "        [0.6232],\n",
            "        [0.6327],\n",
            "        [0.6421],\n",
            "        [0.6516],\n",
            "        [0.6610],\n",
            "        [0.6705],\n",
            "        [0.6800],\n",
            "        [0.6894],\n",
            "        [0.6989],\n",
            "        [0.7083],\n",
            "        [0.7178],\n",
            "        [0.7272],\n",
            "        [0.7367],\n",
            "        [0.7461],\n",
            "        [0.7556]], grad_fn=<AddBackward0>)\n",
            "Epoch: 40 | MAE Train Loss: 0.04543796554207802 | MAE Test Loss: 0.11360953003168106 \n",
            "tensor([[0.3868],\n",
            "        [0.3963],\n",
            "        [0.4058],\n",
            "        [0.4153],\n",
            "        [0.4248],\n",
            "        [0.4343],\n",
            "        [0.4438],\n",
            "        [0.4533],\n",
            "        [0.4628],\n",
            "        [0.4723],\n",
            "        [0.4818],\n",
            "        [0.4913],\n",
            "        [0.5008],\n",
            "        [0.5103],\n",
            "        [0.5198],\n",
            "        [0.5293],\n",
            "        [0.5387],\n",
            "        [0.5482],\n",
            "        [0.5577],\n",
            "        [0.5672],\n",
            "        [0.5767],\n",
            "        [0.5862],\n",
            "        [0.5957],\n",
            "        [0.6052],\n",
            "        [0.6147],\n",
            "        [0.6242],\n",
            "        [0.6337],\n",
            "        [0.6432],\n",
            "        [0.6527],\n",
            "        [0.6622],\n",
            "        [0.6717],\n",
            "        [0.6812],\n",
            "        [0.6907],\n",
            "        [0.7002],\n",
            "        [0.7097],\n",
            "        [0.7192],\n",
            "        [0.7287],\n",
            "        [0.7382],\n",
            "        [0.7477],\n",
            "        [0.7572]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3868],\n",
            "        [0.3963],\n",
            "        [0.4059],\n",
            "        [0.4154],\n",
            "        [0.4250],\n",
            "        [0.4345],\n",
            "        [0.4440],\n",
            "        [0.4536],\n",
            "        [0.4631],\n",
            "        [0.4726],\n",
            "        [0.4822],\n",
            "        [0.4917],\n",
            "        [0.5012],\n",
            "        [0.5108],\n",
            "        [0.5203],\n",
            "        [0.5299],\n",
            "        [0.5394],\n",
            "        [0.5489],\n",
            "        [0.5585],\n",
            "        [0.5680],\n",
            "        [0.5775],\n",
            "        [0.5871],\n",
            "        [0.5966],\n",
            "        [0.6061],\n",
            "        [0.6157],\n",
            "        [0.6252],\n",
            "        [0.6348],\n",
            "        [0.6443],\n",
            "        [0.6538],\n",
            "        [0.6634],\n",
            "        [0.6729],\n",
            "        [0.6824],\n",
            "        [0.6920],\n",
            "        [0.7015],\n",
            "        [0.7110],\n",
            "        [0.7206],\n",
            "        [0.7301],\n",
            "        [0.7396],\n",
            "        [0.7492],\n",
            "        [0.7587]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3868],\n",
            "        [0.3964],\n",
            "        [0.4060],\n",
            "        [0.4155],\n",
            "        [0.4251],\n",
            "        [0.4347],\n",
            "        [0.4443],\n",
            "        [0.4538],\n",
            "        [0.4634],\n",
            "        [0.4730],\n",
            "        [0.4826],\n",
            "        [0.4921],\n",
            "        [0.5017],\n",
            "        [0.5113],\n",
            "        [0.5209],\n",
            "        [0.5305],\n",
            "        [0.5400],\n",
            "        [0.5496],\n",
            "        [0.5592],\n",
            "        [0.5688],\n",
            "        [0.5783],\n",
            "        [0.5879],\n",
            "        [0.5975],\n",
            "        [0.6071],\n",
            "        [0.6166],\n",
            "        [0.6262],\n",
            "        [0.6358],\n",
            "        [0.6454],\n",
            "        [0.6549],\n",
            "        [0.6645],\n",
            "        [0.6741],\n",
            "        [0.6837],\n",
            "        [0.6932],\n",
            "        [0.7028],\n",
            "        [0.7124],\n",
            "        [0.7220],\n",
            "        [0.7316],\n",
            "        [0.7411],\n",
            "        [0.7507],\n",
            "        [0.7603]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3868],\n",
            "        [0.3964],\n",
            "        [0.4060],\n",
            "        [0.4157],\n",
            "        [0.4253],\n",
            "        [0.4349],\n",
            "        [0.4445],\n",
            "        [0.4541],\n",
            "        [0.4637],\n",
            "        [0.4734],\n",
            "        [0.4830],\n",
            "        [0.4926],\n",
            "        [0.5022],\n",
            "        [0.5118],\n",
            "        [0.5214],\n",
            "        [0.5311],\n",
            "        [0.5407],\n",
            "        [0.5503],\n",
            "        [0.5599],\n",
            "        [0.5695],\n",
            "        [0.5791],\n",
            "        [0.5887],\n",
            "        [0.5984],\n",
            "        [0.6080],\n",
            "        [0.6176],\n",
            "        [0.6272],\n",
            "        [0.6368],\n",
            "        [0.6464],\n",
            "        [0.6561],\n",
            "        [0.6657],\n",
            "        [0.6753],\n",
            "        [0.6849],\n",
            "        [0.6945],\n",
            "        [0.7041],\n",
            "        [0.7138],\n",
            "        [0.7234],\n",
            "        [0.7330],\n",
            "        [0.7426],\n",
            "        [0.7522],\n",
            "        [0.7618]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3868],\n",
            "        [0.3965],\n",
            "        [0.4061],\n",
            "        [0.4158],\n",
            "        [0.4254],\n",
            "        [0.4351],\n",
            "        [0.4447],\n",
            "        [0.4544],\n",
            "        [0.4641],\n",
            "        [0.4737],\n",
            "        [0.4834],\n",
            "        [0.4930],\n",
            "        [0.5027],\n",
            "        [0.5123],\n",
            "        [0.5220],\n",
            "        [0.5317],\n",
            "        [0.5413],\n",
            "        [0.5510],\n",
            "        [0.5606],\n",
            "        [0.5703],\n",
            "        [0.5799],\n",
            "        [0.5896],\n",
            "        [0.5992],\n",
            "        [0.6089],\n",
            "        [0.6186],\n",
            "        [0.6282],\n",
            "        [0.6379],\n",
            "        [0.6475],\n",
            "        [0.6572],\n",
            "        [0.6668],\n",
            "        [0.6765],\n",
            "        [0.6862],\n",
            "        [0.6958],\n",
            "        [0.7055],\n",
            "        [0.7151],\n",
            "        [0.7248],\n",
            "        [0.7344],\n",
            "        [0.7441],\n",
            "        [0.7537],\n",
            "        [0.7634]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3868],\n",
            "        [0.3965],\n",
            "        [0.4062],\n",
            "        [0.4159],\n",
            "        [0.4256],\n",
            "        [0.4353],\n",
            "        [0.4450],\n",
            "        [0.4547],\n",
            "        [0.4644],\n",
            "        [0.4741],\n",
            "        [0.4838],\n",
            "        [0.4935],\n",
            "        [0.5032],\n",
            "        [0.5129],\n",
            "        [0.5226],\n",
            "        [0.5323],\n",
            "        [0.5419],\n",
            "        [0.5516],\n",
            "        [0.5613],\n",
            "        [0.5710],\n",
            "        [0.5807],\n",
            "        [0.5904],\n",
            "        [0.6001],\n",
            "        [0.6098],\n",
            "        [0.6195],\n",
            "        [0.6292],\n",
            "        [0.6389],\n",
            "        [0.6486],\n",
            "        [0.6583],\n",
            "        [0.6680],\n",
            "        [0.6777],\n",
            "        [0.6874],\n",
            "        [0.6971],\n",
            "        [0.7068],\n",
            "        [0.7165],\n",
            "        [0.7262],\n",
            "        [0.7359],\n",
            "        [0.7456],\n",
            "        [0.7553],\n",
            "        [0.7650]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3863],\n",
            "        [0.3960],\n",
            "        [0.4058],\n",
            "        [0.4155],\n",
            "        [0.4252],\n",
            "        [0.4350],\n",
            "        [0.4447],\n",
            "        [0.4544],\n",
            "        [0.4642],\n",
            "        [0.4739],\n",
            "        [0.4836],\n",
            "        [0.4934],\n",
            "        [0.5031],\n",
            "        [0.5128],\n",
            "        [0.5226],\n",
            "        [0.5323],\n",
            "        [0.5420],\n",
            "        [0.5518],\n",
            "        [0.5615],\n",
            "        [0.5712],\n",
            "        [0.5810],\n",
            "        [0.5907],\n",
            "        [0.6004],\n",
            "        [0.6102],\n",
            "        [0.6199],\n",
            "        [0.6296],\n",
            "        [0.6393],\n",
            "        [0.6491],\n",
            "        [0.6588],\n",
            "        [0.6685],\n",
            "        [0.6783],\n",
            "        [0.6880],\n",
            "        [0.6977],\n",
            "        [0.7075],\n",
            "        [0.7172],\n",
            "        [0.7269],\n",
            "        [0.7367],\n",
            "        [0.7464],\n",
            "        [0.7561],\n",
            "        [0.7659]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3858],\n",
            "        [0.3956],\n",
            "        [0.4053],\n",
            "        [0.4151],\n",
            "        [0.4249],\n",
            "        [0.4347],\n",
            "        [0.4444],\n",
            "        [0.4542],\n",
            "        [0.4640],\n",
            "        [0.4737],\n",
            "        [0.4835],\n",
            "        [0.4933],\n",
            "        [0.5030],\n",
            "        [0.5128],\n",
            "        [0.5226],\n",
            "        [0.5323],\n",
            "        [0.5421],\n",
            "        [0.5519],\n",
            "        [0.5616],\n",
            "        [0.5714],\n",
            "        [0.5812],\n",
            "        [0.5909],\n",
            "        [0.6007],\n",
            "        [0.6105],\n",
            "        [0.6202],\n",
            "        [0.6300],\n",
            "        [0.6398],\n",
            "        [0.6496],\n",
            "        [0.6593],\n",
            "        [0.6691],\n",
            "        [0.6789],\n",
            "        [0.6886],\n",
            "        [0.6984],\n",
            "        [0.7082],\n",
            "        [0.7179],\n",
            "        [0.7277],\n",
            "        [0.7375],\n",
            "        [0.7472],\n",
            "        [0.7570],\n",
            "        [0.7668]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3853],\n",
            "        [0.3951],\n",
            "        [0.4049],\n",
            "        [0.4147],\n",
            "        [0.4245],\n",
            "        [0.4343],\n",
            "        [0.4441],\n",
            "        [0.4539],\n",
            "        [0.4637],\n",
            "        [0.4735],\n",
            "        [0.4834],\n",
            "        [0.4932],\n",
            "        [0.5030],\n",
            "        [0.5128],\n",
            "        [0.5226],\n",
            "        [0.5324],\n",
            "        [0.5422],\n",
            "        [0.5520],\n",
            "        [0.5618],\n",
            "        [0.5716],\n",
            "        [0.5814],\n",
            "        [0.5912],\n",
            "        [0.6010],\n",
            "        [0.6108],\n",
            "        [0.6206],\n",
            "        [0.6304],\n",
            "        [0.6402],\n",
            "        [0.6500],\n",
            "        [0.6598],\n",
            "        [0.6696],\n",
            "        [0.6794],\n",
            "        [0.6892],\n",
            "        [0.6990],\n",
            "        [0.7088],\n",
            "        [0.7187],\n",
            "        [0.7285],\n",
            "        [0.7383],\n",
            "        [0.7481],\n",
            "        [0.7579],\n",
            "        [0.7677]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3848],\n",
            "        [0.3946],\n",
            "        [0.4045],\n",
            "        [0.4143],\n",
            "        [0.4242],\n",
            "        [0.4340],\n",
            "        [0.4439],\n",
            "        [0.4537],\n",
            "        [0.4635],\n",
            "        [0.4734],\n",
            "        [0.4832],\n",
            "        [0.4931],\n",
            "        [0.5029],\n",
            "        [0.5127],\n",
            "        [0.5226],\n",
            "        [0.5324],\n",
            "        [0.5423],\n",
            "        [0.5521],\n",
            "        [0.5619],\n",
            "        [0.5718],\n",
            "        [0.5816],\n",
            "        [0.5915],\n",
            "        [0.6013],\n",
            "        [0.6111],\n",
            "        [0.6210],\n",
            "        [0.6308],\n",
            "        [0.6407],\n",
            "        [0.6505],\n",
            "        [0.6603],\n",
            "        [0.6702],\n",
            "        [0.6800],\n",
            "        [0.6899],\n",
            "        [0.6997],\n",
            "        [0.7095],\n",
            "        [0.7194],\n",
            "        [0.7292],\n",
            "        [0.7391],\n",
            "        [0.7489],\n",
            "        [0.7587],\n",
            "        [0.7686]], grad_fn=<AddBackward0>)\n",
            "Epoch: 50 | MAE Train Loss: 0.04167863354086876 | MAE Test Loss: 0.09919948130846024 \n",
            "tensor([[0.3843],\n",
            "        [0.3942],\n",
            "        [0.4041],\n",
            "        [0.4139],\n",
            "        [0.4238],\n",
            "        [0.4337],\n",
            "        [0.4436],\n",
            "        [0.4534],\n",
            "        [0.4633],\n",
            "        [0.4732],\n",
            "        [0.4831],\n",
            "        [0.4929],\n",
            "        [0.5028],\n",
            "        [0.5127],\n",
            "        [0.5226],\n",
            "        [0.5325],\n",
            "        [0.5423],\n",
            "        [0.5522],\n",
            "        [0.5621],\n",
            "        [0.5720],\n",
            "        [0.5818],\n",
            "        [0.5917],\n",
            "        [0.6016],\n",
            "        [0.6115],\n",
            "        [0.6213],\n",
            "        [0.6312],\n",
            "        [0.6411],\n",
            "        [0.6510],\n",
            "        [0.6608],\n",
            "        [0.6707],\n",
            "        [0.6806],\n",
            "        [0.6905],\n",
            "        [0.7003],\n",
            "        [0.7102],\n",
            "        [0.7201],\n",
            "        [0.7300],\n",
            "        [0.7399],\n",
            "        [0.7497],\n",
            "        [0.7596],\n",
            "        [0.7695]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3838],\n",
            "        [0.3937],\n",
            "        [0.4036],\n",
            "        [0.4135],\n",
            "        [0.4235],\n",
            "        [0.4334],\n",
            "        [0.4433],\n",
            "        [0.4532],\n",
            "        [0.4631],\n",
            "        [0.4730],\n",
            "        [0.4829],\n",
            "        [0.4928],\n",
            "        [0.5028],\n",
            "        [0.5127],\n",
            "        [0.5226],\n",
            "        [0.5325],\n",
            "        [0.5424],\n",
            "        [0.5523],\n",
            "        [0.5622],\n",
            "        [0.5721],\n",
            "        [0.5821],\n",
            "        [0.5920],\n",
            "        [0.6019],\n",
            "        [0.6118],\n",
            "        [0.6217],\n",
            "        [0.6316],\n",
            "        [0.6415],\n",
            "        [0.6514],\n",
            "        [0.6614],\n",
            "        [0.6713],\n",
            "        [0.6812],\n",
            "        [0.6911],\n",
            "        [0.7010],\n",
            "        [0.7109],\n",
            "        [0.7208],\n",
            "        [0.7307],\n",
            "        [0.7406],\n",
            "        [0.7506],\n",
            "        [0.7605],\n",
            "        [0.7704]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3833],\n",
            "        [0.3933],\n",
            "        [0.4032],\n",
            "        [0.4132],\n",
            "        [0.4231],\n",
            "        [0.4331],\n",
            "        [0.4430],\n",
            "        [0.4529],\n",
            "        [0.4629],\n",
            "        [0.4728],\n",
            "        [0.4828],\n",
            "        [0.4927],\n",
            "        [0.5027],\n",
            "        [0.5126],\n",
            "        [0.5226],\n",
            "        [0.5325],\n",
            "        [0.5425],\n",
            "        [0.5524],\n",
            "        [0.5624],\n",
            "        [0.5723],\n",
            "        [0.5823],\n",
            "        [0.5922],\n",
            "        [0.6022],\n",
            "        [0.6121],\n",
            "        [0.6221],\n",
            "        [0.6320],\n",
            "        [0.6420],\n",
            "        [0.6519],\n",
            "        [0.6619],\n",
            "        [0.6718],\n",
            "        [0.6818],\n",
            "        [0.6917],\n",
            "        [0.7017],\n",
            "        [0.7116],\n",
            "        [0.7215],\n",
            "        [0.7315],\n",
            "        [0.7414],\n",
            "        [0.7514],\n",
            "        [0.7613],\n",
            "        [0.7713]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3828],\n",
            "        [0.3928],\n",
            "        [0.4028],\n",
            "        [0.4128],\n",
            "        [0.4227],\n",
            "        [0.4327],\n",
            "        [0.4427],\n",
            "        [0.4527],\n",
            "        [0.4627],\n",
            "        [0.4727],\n",
            "        [0.4827],\n",
            "        [0.4926],\n",
            "        [0.5026],\n",
            "        [0.5126],\n",
            "        [0.5226],\n",
            "        [0.5326],\n",
            "        [0.5426],\n",
            "        [0.5525],\n",
            "        [0.5625],\n",
            "        [0.5725],\n",
            "        [0.5825],\n",
            "        [0.5925],\n",
            "        [0.6025],\n",
            "        [0.6124],\n",
            "        [0.6224],\n",
            "        [0.6324],\n",
            "        [0.6424],\n",
            "        [0.6524],\n",
            "        [0.6624],\n",
            "        [0.6724],\n",
            "        [0.6823],\n",
            "        [0.6923],\n",
            "        [0.7023],\n",
            "        [0.7123],\n",
            "        [0.7223],\n",
            "        [0.7323],\n",
            "        [0.7422],\n",
            "        [0.7522],\n",
            "        [0.7622],\n",
            "        [0.7722]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3823],\n",
            "        [0.3923],\n",
            "        [0.4023],\n",
            "        [0.4124],\n",
            "        [0.4224],\n",
            "        [0.4324],\n",
            "        [0.4424],\n",
            "        [0.4525],\n",
            "        [0.4625],\n",
            "        [0.4725],\n",
            "        [0.4825],\n",
            "        [0.4925],\n",
            "        [0.5026],\n",
            "        [0.5126],\n",
            "        [0.5226],\n",
            "        [0.5326],\n",
            "        [0.5426],\n",
            "        [0.5527],\n",
            "        [0.5627],\n",
            "        [0.5727],\n",
            "        [0.5827],\n",
            "        [0.5927],\n",
            "        [0.6028],\n",
            "        [0.6128],\n",
            "        [0.6228],\n",
            "        [0.6328],\n",
            "        [0.6428],\n",
            "        [0.6529],\n",
            "        [0.6629],\n",
            "        [0.6729],\n",
            "        [0.6829],\n",
            "        [0.6929],\n",
            "        [0.7030],\n",
            "        [0.7130],\n",
            "        [0.7230],\n",
            "        [0.7330],\n",
            "        [0.7430],\n",
            "        [0.7531],\n",
            "        [0.7631],\n",
            "        [0.7731]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3818],\n",
            "        [0.3919],\n",
            "        [0.4019],\n",
            "        [0.4120],\n",
            "        [0.4220],\n",
            "        [0.4321],\n",
            "        [0.4421],\n",
            "        [0.4522],\n",
            "        [0.4623],\n",
            "        [0.4723],\n",
            "        [0.4824],\n",
            "        [0.4924],\n",
            "        [0.5025],\n",
            "        [0.5125],\n",
            "        [0.5226],\n",
            "        [0.5327],\n",
            "        [0.5427],\n",
            "        [0.5528],\n",
            "        [0.5628],\n",
            "        [0.5729],\n",
            "        [0.5829],\n",
            "        [0.5930],\n",
            "        [0.6030],\n",
            "        [0.6131],\n",
            "        [0.6232],\n",
            "        [0.6332],\n",
            "        [0.6433],\n",
            "        [0.6533],\n",
            "        [0.6634],\n",
            "        [0.6734],\n",
            "        [0.6835],\n",
            "        [0.6936],\n",
            "        [0.7036],\n",
            "        [0.7137],\n",
            "        [0.7237],\n",
            "        [0.7338],\n",
            "        [0.7438],\n",
            "        [0.7539],\n",
            "        [0.7639],\n",
            "        [0.7740]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3813],\n",
            "        [0.3914],\n",
            "        [0.4015],\n",
            "        [0.4116],\n",
            "        [0.4217],\n",
            "        [0.4318],\n",
            "        [0.4419],\n",
            "        [0.4520],\n",
            "        [0.4620],\n",
            "        [0.4721],\n",
            "        [0.4822],\n",
            "        [0.4923],\n",
            "        [0.5024],\n",
            "        [0.5125],\n",
            "        [0.5226],\n",
            "        [0.5327],\n",
            "        [0.5428],\n",
            "        [0.5529],\n",
            "        [0.5630],\n",
            "        [0.5731],\n",
            "        [0.5832],\n",
            "        [0.5932],\n",
            "        [0.6033],\n",
            "        [0.6134],\n",
            "        [0.6235],\n",
            "        [0.6336],\n",
            "        [0.6437],\n",
            "        [0.6538],\n",
            "        [0.6639],\n",
            "        [0.6740],\n",
            "        [0.6841],\n",
            "        [0.6942],\n",
            "        [0.7043],\n",
            "        [0.7144],\n",
            "        [0.7244],\n",
            "        [0.7345],\n",
            "        [0.7446],\n",
            "        [0.7547],\n",
            "        [0.7648],\n",
            "        [0.7749]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3808],\n",
            "        [0.3909],\n",
            "        [0.4011],\n",
            "        [0.4112],\n",
            "        [0.4213],\n",
            "        [0.4315],\n",
            "        [0.4416],\n",
            "        [0.4517],\n",
            "        [0.4618],\n",
            "        [0.4720],\n",
            "        [0.4821],\n",
            "        [0.4922],\n",
            "        [0.5023],\n",
            "        [0.5125],\n",
            "        [0.5226],\n",
            "        [0.5327],\n",
            "        [0.5429],\n",
            "        [0.5530],\n",
            "        [0.5631],\n",
            "        [0.5732],\n",
            "        [0.5834],\n",
            "        [0.5935],\n",
            "        [0.6036],\n",
            "        [0.6138],\n",
            "        [0.6239],\n",
            "        [0.6340],\n",
            "        [0.6441],\n",
            "        [0.6543],\n",
            "        [0.6644],\n",
            "        [0.6745],\n",
            "        [0.6847],\n",
            "        [0.6948],\n",
            "        [0.7049],\n",
            "        [0.7150],\n",
            "        [0.7252],\n",
            "        [0.7353],\n",
            "        [0.7454],\n",
            "        [0.7556],\n",
            "        [0.7657],\n",
            "        [0.7758]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3803],\n",
            "        [0.3905],\n",
            "        [0.4006],\n",
            "        [0.4108],\n",
            "        [0.4210],\n",
            "        [0.4311],\n",
            "        [0.4413],\n",
            "        [0.4515],\n",
            "        [0.4616],\n",
            "        [0.4718],\n",
            "        [0.4820],\n",
            "        [0.4921],\n",
            "        [0.5023],\n",
            "        [0.5124],\n",
            "        [0.5226],\n",
            "        [0.5328],\n",
            "        [0.5429],\n",
            "        [0.5531],\n",
            "        [0.5633],\n",
            "        [0.5734],\n",
            "        [0.5836],\n",
            "        [0.5938],\n",
            "        [0.6039],\n",
            "        [0.6141],\n",
            "        [0.6243],\n",
            "        [0.6344],\n",
            "        [0.6446],\n",
            "        [0.6547],\n",
            "        [0.6649],\n",
            "        [0.6751],\n",
            "        [0.6852],\n",
            "        [0.6954],\n",
            "        [0.7056],\n",
            "        [0.7157],\n",
            "        [0.7259],\n",
            "        [0.7361],\n",
            "        [0.7462],\n",
            "        [0.7564],\n",
            "        [0.7665],\n",
            "        [0.7767]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3798],\n",
            "        [0.3900],\n",
            "        [0.4002],\n",
            "        [0.4104],\n",
            "        [0.4206],\n",
            "        [0.4308],\n",
            "        [0.4410],\n",
            "        [0.4512],\n",
            "        [0.4614],\n",
            "        [0.4716],\n",
            "        [0.4818],\n",
            "        [0.4920],\n",
            "        [0.5022],\n",
            "        [0.5124],\n",
            "        [0.5226],\n",
            "        [0.5328],\n",
            "        [0.5430],\n",
            "        [0.5532],\n",
            "        [0.5634],\n",
            "        [0.5736],\n",
            "        [0.5838],\n",
            "        [0.5940],\n",
            "        [0.6042],\n",
            "        [0.6144],\n",
            "        [0.6246],\n",
            "        [0.6348],\n",
            "        [0.6450],\n",
            "        [0.6552],\n",
            "        [0.6654],\n",
            "        [0.6756],\n",
            "        [0.6858],\n",
            "        [0.6960],\n",
            "        [0.7062],\n",
            "        [0.7164],\n",
            "        [0.7266],\n",
            "        [0.7368],\n",
            "        [0.7470],\n",
            "        [0.7572],\n",
            "        [0.7674],\n",
            "        [0.7776]], grad_fn=<AddBackward0>)\n",
            "Epoch: 60 | MAE Train Loss: 0.03818932920694351 | MAE Test Loss: 0.08886633068323135 \n",
            "tensor([[0.3788],\n",
            "        [0.3890],\n",
            "        [0.3993],\n",
            "        [0.4095],\n",
            "        [0.4197],\n",
            "        [0.4300],\n",
            "        [0.4402],\n",
            "        [0.4504],\n",
            "        [0.4607],\n",
            "        [0.4709],\n",
            "        [0.4811],\n",
            "        [0.4914],\n",
            "        [0.5016],\n",
            "        [0.5118],\n",
            "        [0.5221],\n",
            "        [0.5323],\n",
            "        [0.5425],\n",
            "        [0.5528],\n",
            "        [0.5630],\n",
            "        [0.5732],\n",
            "        [0.5834],\n",
            "        [0.5937],\n",
            "        [0.6039],\n",
            "        [0.6141],\n",
            "        [0.6244],\n",
            "        [0.6346],\n",
            "        [0.6448],\n",
            "        [0.6551],\n",
            "        [0.6653],\n",
            "        [0.6755],\n",
            "        [0.6858],\n",
            "        [0.6960],\n",
            "        [0.7062],\n",
            "        [0.7165],\n",
            "        [0.7267],\n",
            "        [0.7369],\n",
            "        [0.7472],\n",
            "        [0.7574],\n",
            "        [0.7676],\n",
            "        [0.7779]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3783],\n",
            "        [0.3886],\n",
            "        [0.3988],\n",
            "        [0.4091],\n",
            "        [0.4194],\n",
            "        [0.4296],\n",
            "        [0.4399],\n",
            "        [0.4502],\n",
            "        [0.4605],\n",
            "        [0.4707],\n",
            "        [0.4810],\n",
            "        [0.4913],\n",
            "        [0.5015],\n",
            "        [0.5118],\n",
            "        [0.5221],\n",
            "        [0.5323],\n",
            "        [0.5426],\n",
            "        [0.5529],\n",
            "        [0.5631],\n",
            "        [0.5734],\n",
            "        [0.5837],\n",
            "        [0.5939],\n",
            "        [0.6042],\n",
            "        [0.6145],\n",
            "        [0.6247],\n",
            "        [0.6350],\n",
            "        [0.6453],\n",
            "        [0.6555],\n",
            "        [0.6658],\n",
            "        [0.6761],\n",
            "        [0.6863],\n",
            "        [0.6966],\n",
            "        [0.7069],\n",
            "        [0.7172],\n",
            "        [0.7274],\n",
            "        [0.7377],\n",
            "        [0.7480],\n",
            "        [0.7582],\n",
            "        [0.7685],\n",
            "        [0.7788]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3778],\n",
            "        [0.3881],\n",
            "        [0.3984],\n",
            "        [0.4087],\n",
            "        [0.4190],\n",
            "        [0.4293],\n",
            "        [0.4396],\n",
            "        [0.4499],\n",
            "        [0.4602],\n",
            "        [0.4705],\n",
            "        [0.4808],\n",
            "        [0.4912],\n",
            "        [0.5015],\n",
            "        [0.5118],\n",
            "        [0.5221],\n",
            "        [0.5324],\n",
            "        [0.5427],\n",
            "        [0.5530],\n",
            "        [0.5633],\n",
            "        [0.5736],\n",
            "        [0.5839],\n",
            "        [0.5942],\n",
            "        [0.6045],\n",
            "        [0.6148],\n",
            "        [0.6251],\n",
            "        [0.6354],\n",
            "        [0.6457],\n",
            "        [0.6560],\n",
            "        [0.6663],\n",
            "        [0.6766],\n",
            "        [0.6869],\n",
            "        [0.6972],\n",
            "        [0.7075],\n",
            "        [0.7178],\n",
            "        [0.7281],\n",
            "        [0.7384],\n",
            "        [0.7488],\n",
            "        [0.7591],\n",
            "        [0.7694],\n",
            "        [0.7797]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3768],\n",
            "        [0.3871],\n",
            "        [0.3975],\n",
            "        [0.4078],\n",
            "        [0.4182],\n",
            "        [0.4285],\n",
            "        [0.4388],\n",
            "        [0.4492],\n",
            "        [0.4595],\n",
            "        [0.4698],\n",
            "        [0.4802],\n",
            "        [0.4905],\n",
            "        [0.5008],\n",
            "        [0.5112],\n",
            "        [0.5215],\n",
            "        [0.5318],\n",
            "        [0.5422],\n",
            "        [0.5525],\n",
            "        [0.5629],\n",
            "        [0.5732],\n",
            "        [0.5835],\n",
            "        [0.5939],\n",
            "        [0.6042],\n",
            "        [0.6145],\n",
            "        [0.6249],\n",
            "        [0.6352],\n",
            "        [0.6455],\n",
            "        [0.6559],\n",
            "        [0.6662],\n",
            "        [0.6765],\n",
            "        [0.6869],\n",
            "        [0.6972],\n",
            "        [0.7076],\n",
            "        [0.7179],\n",
            "        [0.7282],\n",
            "        [0.7386],\n",
            "        [0.7489],\n",
            "        [0.7592],\n",
            "        [0.7696],\n",
            "        [0.7799]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3763],\n",
            "        [0.3867],\n",
            "        [0.3971],\n",
            "        [0.4074],\n",
            "        [0.4178],\n",
            "        [0.4282],\n",
            "        [0.4385],\n",
            "        [0.4489],\n",
            "        [0.4593],\n",
            "        [0.4697],\n",
            "        [0.4800],\n",
            "        [0.4904],\n",
            "        [0.5008],\n",
            "        [0.5111],\n",
            "        [0.5215],\n",
            "        [0.5319],\n",
            "        [0.5423],\n",
            "        [0.5526],\n",
            "        [0.5630],\n",
            "        [0.5734],\n",
            "        [0.5837],\n",
            "        [0.5941],\n",
            "        [0.6045],\n",
            "        [0.6149],\n",
            "        [0.6252],\n",
            "        [0.6356],\n",
            "        [0.6460],\n",
            "        [0.6563],\n",
            "        [0.6667],\n",
            "        [0.6771],\n",
            "        [0.6875],\n",
            "        [0.6978],\n",
            "        [0.7082],\n",
            "        [0.7186],\n",
            "        [0.7290],\n",
            "        [0.7393],\n",
            "        [0.7497],\n",
            "        [0.7601],\n",
            "        [0.7704],\n",
            "        [0.7808]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3753],\n",
            "        [0.3857],\n",
            "        [0.3961],\n",
            "        [0.4065],\n",
            "        [0.4169],\n",
            "        [0.4273],\n",
            "        [0.4377],\n",
            "        [0.4481],\n",
            "        [0.4585],\n",
            "        [0.4689],\n",
            "        [0.4793],\n",
            "        [0.4897],\n",
            "        [0.5002],\n",
            "        [0.5106],\n",
            "        [0.5210],\n",
            "        [0.5314],\n",
            "        [0.5418],\n",
            "        [0.5522],\n",
            "        [0.5626],\n",
            "        [0.5730],\n",
            "        [0.5834],\n",
            "        [0.5938],\n",
            "        [0.6042],\n",
            "        [0.6146],\n",
            "        [0.6250],\n",
            "        [0.6354],\n",
            "        [0.6458],\n",
            "        [0.6562],\n",
            "        [0.6666],\n",
            "        [0.6770],\n",
            "        [0.6874],\n",
            "        [0.6978],\n",
            "        [0.7082],\n",
            "        [0.7186],\n",
            "        [0.7290],\n",
            "        [0.7394],\n",
            "        [0.7498],\n",
            "        [0.7602],\n",
            "        [0.7706],\n",
            "        [0.7811]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3748],\n",
            "        [0.3852],\n",
            "        [0.3957],\n",
            "        [0.4061],\n",
            "        [0.4166],\n",
            "        [0.4270],\n",
            "        [0.4374],\n",
            "        [0.4479],\n",
            "        [0.4583],\n",
            "        [0.4688],\n",
            "        [0.4792],\n",
            "        [0.4896],\n",
            "        [0.5001],\n",
            "        [0.5105],\n",
            "        [0.5210],\n",
            "        [0.5314],\n",
            "        [0.5418],\n",
            "        [0.5523],\n",
            "        [0.5627],\n",
            "        [0.5732],\n",
            "        [0.5836],\n",
            "        [0.5940],\n",
            "        [0.6045],\n",
            "        [0.6149],\n",
            "        [0.6254],\n",
            "        [0.6358],\n",
            "        [0.6462],\n",
            "        [0.6567],\n",
            "        [0.6671],\n",
            "        [0.6776],\n",
            "        [0.6880],\n",
            "        [0.6984],\n",
            "        [0.7089],\n",
            "        [0.7193],\n",
            "        [0.7298],\n",
            "        [0.7402],\n",
            "        [0.7506],\n",
            "        [0.7611],\n",
            "        [0.7715],\n",
            "        [0.7820]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3738],\n",
            "        [0.3843],\n",
            "        [0.3948],\n",
            "        [0.4052],\n",
            "        [0.4157],\n",
            "        [0.4262],\n",
            "        [0.4366],\n",
            "        [0.4471],\n",
            "        [0.4576],\n",
            "        [0.4681],\n",
            "        [0.4785],\n",
            "        [0.4890],\n",
            "        [0.4995],\n",
            "        [0.5099],\n",
            "        [0.5204],\n",
            "        [0.5309],\n",
            "        [0.5414],\n",
            "        [0.5518],\n",
            "        [0.5623],\n",
            "        [0.5728],\n",
            "        [0.5832],\n",
            "        [0.5937],\n",
            "        [0.6042],\n",
            "        [0.6147],\n",
            "        [0.6251],\n",
            "        [0.6356],\n",
            "        [0.6461],\n",
            "        [0.6565],\n",
            "        [0.6670],\n",
            "        [0.6775],\n",
            "        [0.6880],\n",
            "        [0.6984],\n",
            "        [0.7089],\n",
            "        [0.7194],\n",
            "        [0.7298],\n",
            "        [0.7403],\n",
            "        [0.7508],\n",
            "        [0.7613],\n",
            "        [0.7717],\n",
            "        [0.7822]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3733],\n",
            "        [0.3838],\n",
            "        [0.3943],\n",
            "        [0.4048],\n",
            "        [0.4153],\n",
            "        [0.4258],\n",
            "        [0.4364],\n",
            "        [0.4469],\n",
            "        [0.4574],\n",
            "        [0.4679],\n",
            "        [0.4784],\n",
            "        [0.4889],\n",
            "        [0.4994],\n",
            "        [0.5099],\n",
            "        [0.5204],\n",
            "        [0.5309],\n",
            "        [0.5414],\n",
            "        [0.5519],\n",
            "        [0.5624],\n",
            "        [0.5730],\n",
            "        [0.5835],\n",
            "        [0.5940],\n",
            "        [0.6045],\n",
            "        [0.6150],\n",
            "        [0.6255],\n",
            "        [0.6360],\n",
            "        [0.6465],\n",
            "        [0.6570],\n",
            "        [0.6675],\n",
            "        [0.6780],\n",
            "        [0.6885],\n",
            "        [0.6990],\n",
            "        [0.7095],\n",
            "        [0.7201],\n",
            "        [0.7306],\n",
            "        [0.7411],\n",
            "        [0.7516],\n",
            "        [0.7621],\n",
            "        [0.7726],\n",
            "        [0.7831]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3728],\n",
            "        [0.3834],\n",
            "        [0.3939],\n",
            "        [0.4044],\n",
            "        [0.4150],\n",
            "        [0.4255],\n",
            "        [0.4361],\n",
            "        [0.4466],\n",
            "        [0.4572],\n",
            "        [0.4677],\n",
            "        [0.4782],\n",
            "        [0.4888],\n",
            "        [0.4993],\n",
            "        [0.5099],\n",
            "        [0.5204],\n",
            "        [0.5310],\n",
            "        [0.5415],\n",
            "        [0.5520],\n",
            "        [0.5626],\n",
            "        [0.5731],\n",
            "        [0.5837],\n",
            "        [0.5942],\n",
            "        [0.6048],\n",
            "        [0.6153],\n",
            "        [0.6259],\n",
            "        [0.6364],\n",
            "        [0.6469],\n",
            "        [0.6575],\n",
            "        [0.6680],\n",
            "        [0.6786],\n",
            "        [0.6891],\n",
            "        [0.6997],\n",
            "        [0.7102],\n",
            "        [0.7207],\n",
            "        [0.7313],\n",
            "        [0.7418],\n",
            "        [0.7524],\n",
            "        [0.7629],\n",
            "        [0.7735],\n",
            "        [0.7840]], grad_fn=<AddBackward0>)\n",
            "Epoch: 70 | MAE Train Loss: 0.03476089984178543 | MAE Test Loss: 0.0805937647819519 \n",
            "tensor([[0.3718],\n",
            "        [0.3824],\n",
            "        [0.3930],\n",
            "        [0.4035],\n",
            "        [0.4141],\n",
            "        [0.4247],\n",
            "        [0.4353],\n",
            "        [0.4458],\n",
            "        [0.4564],\n",
            "        [0.4670],\n",
            "        [0.4776],\n",
            "        [0.4881],\n",
            "        [0.4987],\n",
            "        [0.5093],\n",
            "        [0.5199],\n",
            "        [0.5304],\n",
            "        [0.5410],\n",
            "        [0.5516],\n",
            "        [0.5622],\n",
            "        [0.5727],\n",
            "        [0.5833],\n",
            "        [0.5939],\n",
            "        [0.6045],\n",
            "        [0.6150],\n",
            "        [0.6256],\n",
            "        [0.6362],\n",
            "        [0.6468],\n",
            "        [0.6573],\n",
            "        [0.6679],\n",
            "        [0.6785],\n",
            "        [0.6891],\n",
            "        [0.6996],\n",
            "        [0.7102],\n",
            "        [0.7208],\n",
            "        [0.7314],\n",
            "        [0.7419],\n",
            "        [0.7525],\n",
            "        [0.7631],\n",
            "        [0.7737],\n",
            "        [0.7842]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3713],\n",
            "        [0.3819],\n",
            "        [0.3925],\n",
            "        [0.4031],\n",
            "        [0.4138],\n",
            "        [0.4244],\n",
            "        [0.4350],\n",
            "        [0.4456],\n",
            "        [0.4562],\n",
            "        [0.4668],\n",
            "        [0.4774],\n",
            "        [0.4880],\n",
            "        [0.4986],\n",
            "        [0.5093],\n",
            "        [0.5199],\n",
            "        [0.5305],\n",
            "        [0.5411],\n",
            "        [0.5517],\n",
            "        [0.5623],\n",
            "        [0.5729],\n",
            "        [0.5835],\n",
            "        [0.5941],\n",
            "        [0.6048],\n",
            "        [0.6154],\n",
            "        [0.6260],\n",
            "        [0.6366],\n",
            "        [0.6472],\n",
            "        [0.6578],\n",
            "        [0.6684],\n",
            "        [0.6790],\n",
            "        [0.6896],\n",
            "        [0.7003],\n",
            "        [0.7109],\n",
            "        [0.7215],\n",
            "        [0.7321],\n",
            "        [0.7427],\n",
            "        [0.7533],\n",
            "        [0.7639],\n",
            "        [0.7745],\n",
            "        [0.7851]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3703],\n",
            "        [0.3810],\n",
            "        [0.3916],\n",
            "        [0.4022],\n",
            "        [0.4129],\n",
            "        [0.4235],\n",
            "        [0.4342],\n",
            "        [0.4448],\n",
            "        [0.4555],\n",
            "        [0.4661],\n",
            "        [0.4767],\n",
            "        [0.4874],\n",
            "        [0.4980],\n",
            "        [0.5087],\n",
            "        [0.5193],\n",
            "        [0.5300],\n",
            "        [0.5406],\n",
            "        [0.5512],\n",
            "        [0.5619],\n",
            "        [0.5725],\n",
            "        [0.5832],\n",
            "        [0.5938],\n",
            "        [0.6045],\n",
            "        [0.6151],\n",
            "        [0.6257],\n",
            "        [0.6364],\n",
            "        [0.6470],\n",
            "        [0.6577],\n",
            "        [0.6683],\n",
            "        [0.6790],\n",
            "        [0.6896],\n",
            "        [0.7002],\n",
            "        [0.7109],\n",
            "        [0.7215],\n",
            "        [0.7322],\n",
            "        [0.7428],\n",
            "        [0.7535],\n",
            "        [0.7641],\n",
            "        [0.7747],\n",
            "        [0.7854]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3698],\n",
            "        [0.3805],\n",
            "        [0.3912],\n",
            "        [0.4018],\n",
            "        [0.4125],\n",
            "        [0.4232],\n",
            "        [0.4339],\n",
            "        [0.4446],\n",
            "        [0.4552],\n",
            "        [0.4659],\n",
            "        [0.4766],\n",
            "        [0.4873],\n",
            "        [0.4980],\n",
            "        [0.5086],\n",
            "        [0.5193],\n",
            "        [0.5300],\n",
            "        [0.5407],\n",
            "        [0.5514],\n",
            "        [0.5620],\n",
            "        [0.5727],\n",
            "        [0.5834],\n",
            "        [0.5941],\n",
            "        [0.6047],\n",
            "        [0.6154],\n",
            "        [0.6261],\n",
            "        [0.6368],\n",
            "        [0.6475],\n",
            "        [0.6581],\n",
            "        [0.6688],\n",
            "        [0.6795],\n",
            "        [0.6902],\n",
            "        [0.7009],\n",
            "        [0.7115],\n",
            "        [0.7222],\n",
            "        [0.7329],\n",
            "        [0.7436],\n",
            "        [0.7543],\n",
            "        [0.7649],\n",
            "        [0.7756],\n",
            "        [0.7863]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3688],\n",
            "        [0.3795],\n",
            "        [0.3902],\n",
            "        [0.4009],\n",
            "        [0.4117],\n",
            "        [0.4224],\n",
            "        [0.4331],\n",
            "        [0.4438],\n",
            "        [0.4545],\n",
            "        [0.4652],\n",
            "        [0.4759],\n",
            "        [0.4866],\n",
            "        [0.4973],\n",
            "        [0.5081],\n",
            "        [0.5188],\n",
            "        [0.5295],\n",
            "        [0.5402],\n",
            "        [0.5509],\n",
            "        [0.5616],\n",
            "        [0.5723],\n",
            "        [0.5830],\n",
            "        [0.5937],\n",
            "        [0.6044],\n",
            "        [0.6152],\n",
            "        [0.6259],\n",
            "        [0.6366],\n",
            "        [0.6473],\n",
            "        [0.6580],\n",
            "        [0.6687],\n",
            "        [0.6794],\n",
            "        [0.6901],\n",
            "        [0.7008],\n",
            "        [0.7116],\n",
            "        [0.7223],\n",
            "        [0.7330],\n",
            "        [0.7437],\n",
            "        [0.7544],\n",
            "        [0.7651],\n",
            "        [0.7758],\n",
            "        [0.7865]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3683],\n",
            "        [0.3791],\n",
            "        [0.3898],\n",
            "        [0.4006],\n",
            "        [0.4113],\n",
            "        [0.4220],\n",
            "        [0.4328],\n",
            "        [0.4435],\n",
            "        [0.4543],\n",
            "        [0.4650],\n",
            "        [0.4758],\n",
            "        [0.4865],\n",
            "        [0.4973],\n",
            "        [0.5080],\n",
            "        [0.5188],\n",
            "        [0.5295],\n",
            "        [0.5403],\n",
            "        [0.5510],\n",
            "        [0.5618],\n",
            "        [0.5725],\n",
            "        [0.5832],\n",
            "        [0.5940],\n",
            "        [0.6047],\n",
            "        [0.6155],\n",
            "        [0.6262],\n",
            "        [0.6370],\n",
            "        [0.6477],\n",
            "        [0.6585],\n",
            "        [0.6692],\n",
            "        [0.6800],\n",
            "        [0.6907],\n",
            "        [0.7015],\n",
            "        [0.7122],\n",
            "        [0.7230],\n",
            "        [0.7337],\n",
            "        [0.7444],\n",
            "        [0.7552],\n",
            "        [0.7659],\n",
            "        [0.7767],\n",
            "        [0.7874]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3678],\n",
            "        [0.3786],\n",
            "        [0.3894],\n",
            "        [0.4002],\n",
            "        [0.4109],\n",
            "        [0.4217],\n",
            "        [0.4325],\n",
            "        [0.4433],\n",
            "        [0.4541],\n",
            "        [0.4649],\n",
            "        [0.4756],\n",
            "        [0.4864],\n",
            "        [0.4972],\n",
            "        [0.5080],\n",
            "        [0.5188],\n",
            "        [0.5296],\n",
            "        [0.5403],\n",
            "        [0.5511],\n",
            "        [0.5619],\n",
            "        [0.5727],\n",
            "        [0.5835],\n",
            "        [0.5942],\n",
            "        [0.6050],\n",
            "        [0.6158],\n",
            "        [0.6266],\n",
            "        [0.6374],\n",
            "        [0.6482],\n",
            "        [0.6589],\n",
            "        [0.6697],\n",
            "        [0.6805],\n",
            "        [0.6913],\n",
            "        [0.7021],\n",
            "        [0.7129],\n",
            "        [0.7236],\n",
            "        [0.7344],\n",
            "        [0.7452],\n",
            "        [0.7560],\n",
            "        [0.7668],\n",
            "        [0.7776],\n",
            "        [0.7883]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3668],\n",
            "        [0.3776],\n",
            "        [0.3884],\n",
            "        [0.3993],\n",
            "        [0.4101],\n",
            "        [0.4209],\n",
            "        [0.4317],\n",
            "        [0.4425],\n",
            "        [0.4533],\n",
            "        [0.4641],\n",
            "        [0.4750],\n",
            "        [0.4858],\n",
            "        [0.4966],\n",
            "        [0.5074],\n",
            "        [0.5182],\n",
            "        [0.5290],\n",
            "        [0.5398],\n",
            "        [0.5507],\n",
            "        [0.5615],\n",
            "        [0.5723],\n",
            "        [0.5831],\n",
            "        [0.5939],\n",
            "        [0.6047],\n",
            "        [0.6155],\n",
            "        [0.6264],\n",
            "        [0.6372],\n",
            "        [0.6480],\n",
            "        [0.6588],\n",
            "        [0.6696],\n",
            "        [0.6804],\n",
            "        [0.6912],\n",
            "        [0.7021],\n",
            "        [0.7129],\n",
            "        [0.7237],\n",
            "        [0.7345],\n",
            "        [0.7453],\n",
            "        [0.7561],\n",
            "        [0.7670],\n",
            "        [0.7778],\n",
            "        [0.7886]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3663],\n",
            "        [0.3772],\n",
            "        [0.3880],\n",
            "        [0.3989],\n",
            "        [0.4097],\n",
            "        [0.4206],\n",
            "        [0.4314],\n",
            "        [0.4423],\n",
            "        [0.4531],\n",
            "        [0.4640],\n",
            "        [0.4748],\n",
            "        [0.4857],\n",
            "        [0.4965],\n",
            "        [0.5074],\n",
            "        [0.5182],\n",
            "        [0.5291],\n",
            "        [0.5399],\n",
            "        [0.5508],\n",
            "        [0.5616],\n",
            "        [0.5725],\n",
            "        [0.5833],\n",
            "        [0.5942],\n",
            "        [0.6050],\n",
            "        [0.6159],\n",
            "        [0.6267],\n",
            "        [0.6376],\n",
            "        [0.6484],\n",
            "        [0.6593],\n",
            "        [0.6701],\n",
            "        [0.6810],\n",
            "        [0.6918],\n",
            "        [0.7027],\n",
            "        [0.7135],\n",
            "        [0.7244],\n",
            "        [0.7352],\n",
            "        [0.7461],\n",
            "        [0.7569],\n",
            "        [0.7678],\n",
            "        [0.7786],\n",
            "        [0.7895]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3653],\n",
            "        [0.3762],\n",
            "        [0.3871],\n",
            "        [0.3980],\n",
            "        [0.4088],\n",
            "        [0.4197],\n",
            "        [0.4306],\n",
            "        [0.4415],\n",
            "        [0.4524],\n",
            "        [0.4633],\n",
            "        [0.4741],\n",
            "        [0.4850],\n",
            "        [0.4959],\n",
            "        [0.5068],\n",
            "        [0.5177],\n",
            "        [0.5285],\n",
            "        [0.5394],\n",
            "        [0.5503],\n",
            "        [0.5612],\n",
            "        [0.5721],\n",
            "        [0.5830],\n",
            "        [0.5938],\n",
            "        [0.6047],\n",
            "        [0.6156],\n",
            "        [0.6265],\n",
            "        [0.6374],\n",
            "        [0.6483],\n",
            "        [0.6591],\n",
            "        [0.6700],\n",
            "        [0.6809],\n",
            "        [0.6918],\n",
            "        [0.7027],\n",
            "        [0.7135],\n",
            "        [0.7244],\n",
            "        [0.7353],\n",
            "        [0.7462],\n",
            "        [0.7571],\n",
            "        [0.7680],\n",
            "        [0.7788],\n",
            "        [0.7897]], grad_fn=<AddBackward0>)\n",
            "Epoch: 80 | MAE Train Loss: 0.03132382780313492 | MAE Test Loss: 0.07232122868299484 \n",
            "tensor([[0.3648],\n",
            "        [0.3757],\n",
            "        [0.3866],\n",
            "        [0.3976],\n",
            "        [0.4085],\n",
            "        [0.4194],\n",
            "        [0.4303],\n",
            "        [0.4412],\n",
            "        [0.4522],\n",
            "        [0.4631],\n",
            "        [0.4740],\n",
            "        [0.4849],\n",
            "        [0.4958],\n",
            "        [0.5067],\n",
            "        [0.5177],\n",
            "        [0.5286],\n",
            "        [0.5395],\n",
            "        [0.5504],\n",
            "        [0.5613],\n",
            "        [0.5723],\n",
            "        [0.5832],\n",
            "        [0.5941],\n",
            "        [0.6050],\n",
            "        [0.6159],\n",
            "        [0.6269],\n",
            "        [0.6378],\n",
            "        [0.6487],\n",
            "        [0.6596],\n",
            "        [0.6705],\n",
            "        [0.6814],\n",
            "        [0.6924],\n",
            "        [0.7033],\n",
            "        [0.7142],\n",
            "        [0.7251],\n",
            "        [0.7360],\n",
            "        [0.7470],\n",
            "        [0.7579],\n",
            "        [0.7688],\n",
            "        [0.7797],\n",
            "        [0.7906]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3638],\n",
            "        [0.3748],\n",
            "        [0.3857],\n",
            "        [0.3967],\n",
            "        [0.4076],\n",
            "        [0.4186],\n",
            "        [0.4295],\n",
            "        [0.4405],\n",
            "        [0.4514],\n",
            "        [0.4624],\n",
            "        [0.4733],\n",
            "        [0.4843],\n",
            "        [0.4952],\n",
            "        [0.5062],\n",
            "        [0.5171],\n",
            "        [0.5281],\n",
            "        [0.5390],\n",
            "        [0.5500],\n",
            "        [0.5609],\n",
            "        [0.5719],\n",
            "        [0.5828],\n",
            "        [0.5938],\n",
            "        [0.6047],\n",
            "        [0.6157],\n",
            "        [0.6266],\n",
            "        [0.6376],\n",
            "        [0.6485],\n",
            "        [0.6595],\n",
            "        [0.6704],\n",
            "        [0.6814],\n",
            "        [0.6923],\n",
            "        [0.7033],\n",
            "        [0.7142],\n",
            "        [0.7252],\n",
            "        [0.7361],\n",
            "        [0.7471],\n",
            "        [0.7580],\n",
            "        [0.7690],\n",
            "        [0.7799],\n",
            "        [0.7909]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3633],\n",
            "        [0.3743],\n",
            "        [0.3853],\n",
            "        [0.3963],\n",
            "        [0.4073],\n",
            "        [0.4182],\n",
            "        [0.4292],\n",
            "        [0.4402],\n",
            "        [0.4512],\n",
            "        [0.4622],\n",
            "        [0.4732],\n",
            "        [0.4842],\n",
            "        [0.4951],\n",
            "        [0.5061],\n",
            "        [0.5171],\n",
            "        [0.5281],\n",
            "        [0.5391],\n",
            "        [0.5501],\n",
            "        [0.5611],\n",
            "        [0.5720],\n",
            "        [0.5830],\n",
            "        [0.5940],\n",
            "        [0.6050],\n",
            "        [0.6160],\n",
            "        [0.6270],\n",
            "        [0.6380],\n",
            "        [0.6490],\n",
            "        [0.6599],\n",
            "        [0.6709],\n",
            "        [0.6819],\n",
            "        [0.6929],\n",
            "        [0.7039],\n",
            "        [0.7149],\n",
            "        [0.7259],\n",
            "        [0.7368],\n",
            "        [0.7478],\n",
            "        [0.7588],\n",
            "        [0.7698],\n",
            "        [0.7808],\n",
            "        [0.7918]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3623],\n",
            "        [0.3733],\n",
            "        [0.3843],\n",
            "        [0.3954],\n",
            "        [0.4064],\n",
            "        [0.4174],\n",
            "        [0.4284],\n",
            "        [0.4394],\n",
            "        [0.4505],\n",
            "        [0.4615],\n",
            "        [0.4725],\n",
            "        [0.4835],\n",
            "        [0.4945],\n",
            "        [0.5055],\n",
            "        [0.5166],\n",
            "        [0.5276],\n",
            "        [0.5386],\n",
            "        [0.5496],\n",
            "        [0.5606],\n",
            "        [0.5717],\n",
            "        [0.5827],\n",
            "        [0.5937],\n",
            "        [0.6047],\n",
            "        [0.6157],\n",
            "        [0.6267],\n",
            "        [0.6378],\n",
            "        [0.6488],\n",
            "        [0.6598],\n",
            "        [0.6708],\n",
            "        [0.6818],\n",
            "        [0.6928],\n",
            "        [0.7039],\n",
            "        [0.7149],\n",
            "        [0.7259],\n",
            "        [0.7369],\n",
            "        [0.7479],\n",
            "        [0.7590],\n",
            "        [0.7700],\n",
            "        [0.7810],\n",
            "        [0.7920]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3618],\n",
            "        [0.3729],\n",
            "        [0.3839],\n",
            "        [0.3950],\n",
            "        [0.4060],\n",
            "        [0.4171],\n",
            "        [0.4281],\n",
            "        [0.4392],\n",
            "        [0.4502],\n",
            "        [0.4613],\n",
            "        [0.4723],\n",
            "        [0.4834],\n",
            "        [0.4945],\n",
            "        [0.5055],\n",
            "        [0.5166],\n",
            "        [0.5276],\n",
            "        [0.5387],\n",
            "        [0.5497],\n",
            "        [0.5608],\n",
            "        [0.5718],\n",
            "        [0.5829],\n",
            "        [0.5939],\n",
            "        [0.6050],\n",
            "        [0.6161],\n",
            "        [0.6271],\n",
            "        [0.6382],\n",
            "        [0.6492],\n",
            "        [0.6603],\n",
            "        [0.6713],\n",
            "        [0.6824],\n",
            "        [0.6934],\n",
            "        [0.7045],\n",
            "        [0.7155],\n",
            "        [0.7266],\n",
            "        [0.7376],\n",
            "        [0.7487],\n",
            "        [0.7598],\n",
            "        [0.7708],\n",
            "        [0.7819],\n",
            "        [0.7929]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3613],\n",
            "        [0.3724],\n",
            "        [0.3835],\n",
            "        [0.3946],\n",
            "        [0.4057],\n",
            "        [0.4168],\n",
            "        [0.4278],\n",
            "        [0.4389],\n",
            "        [0.4500],\n",
            "        [0.4611],\n",
            "        [0.4722],\n",
            "        [0.4833],\n",
            "        [0.4944],\n",
            "        [0.5055],\n",
            "        [0.5166],\n",
            "        [0.5277],\n",
            "        [0.5387],\n",
            "        [0.5498],\n",
            "        [0.5609],\n",
            "        [0.5720],\n",
            "        [0.5831],\n",
            "        [0.5942],\n",
            "        [0.6053],\n",
            "        [0.6164],\n",
            "        [0.6275],\n",
            "        [0.6386],\n",
            "        [0.6496],\n",
            "        [0.6607],\n",
            "        [0.6718],\n",
            "        [0.6829],\n",
            "        [0.6940],\n",
            "        [0.7051],\n",
            "        [0.7162],\n",
            "        [0.7273],\n",
            "        [0.7384],\n",
            "        [0.7495],\n",
            "        [0.7605],\n",
            "        [0.7716],\n",
            "        [0.7827],\n",
            "        [0.7938]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3603],\n",
            "        [0.3714],\n",
            "        [0.3826],\n",
            "        [0.3937],\n",
            "        [0.4048],\n",
            "        [0.4159],\n",
            "        [0.4270],\n",
            "        [0.4382],\n",
            "        [0.4493],\n",
            "        [0.4604],\n",
            "        [0.4715],\n",
            "        [0.4826],\n",
            "        [0.4938],\n",
            "        [0.5049],\n",
            "        [0.5160],\n",
            "        [0.5271],\n",
            "        [0.5383],\n",
            "        [0.5494],\n",
            "        [0.5605],\n",
            "        [0.5716],\n",
            "        [0.5827],\n",
            "        [0.5939],\n",
            "        [0.6050],\n",
            "        [0.6161],\n",
            "        [0.6272],\n",
            "        [0.6384],\n",
            "        [0.6495],\n",
            "        [0.6606],\n",
            "        [0.6717],\n",
            "        [0.6828],\n",
            "        [0.6940],\n",
            "        [0.7051],\n",
            "        [0.7162],\n",
            "        [0.7273],\n",
            "        [0.7385],\n",
            "        [0.7496],\n",
            "        [0.7607],\n",
            "        [0.7718],\n",
            "        [0.7829],\n",
            "        [0.7941]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3598],\n",
            "        [0.3710],\n",
            "        [0.3821],\n",
            "        [0.3933],\n",
            "        [0.4044],\n",
            "        [0.4156],\n",
            "        [0.4268],\n",
            "        [0.4379],\n",
            "        [0.4491],\n",
            "        [0.4602],\n",
            "        [0.4714],\n",
            "        [0.4825],\n",
            "        [0.4937],\n",
            "        [0.5049],\n",
            "        [0.5160],\n",
            "        [0.5272],\n",
            "        [0.5383],\n",
            "        [0.5495],\n",
            "        [0.5607],\n",
            "        [0.5718],\n",
            "        [0.5830],\n",
            "        [0.5941],\n",
            "        [0.6053],\n",
            "        [0.6164],\n",
            "        [0.6276],\n",
            "        [0.6388],\n",
            "        [0.6499],\n",
            "        [0.6611],\n",
            "        [0.6722],\n",
            "        [0.6834],\n",
            "        [0.6945],\n",
            "        [0.7057],\n",
            "        [0.7169],\n",
            "        [0.7280],\n",
            "        [0.7392],\n",
            "        [0.7503],\n",
            "        [0.7615],\n",
            "        [0.7726],\n",
            "        [0.7838],\n",
            "        [0.7950]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3588],\n",
            "        [0.3700],\n",
            "        [0.3812],\n",
            "        [0.3924],\n",
            "        [0.4036],\n",
            "        [0.4148],\n",
            "        [0.4259],\n",
            "        [0.4371],\n",
            "        [0.4483],\n",
            "        [0.4595],\n",
            "        [0.4707],\n",
            "        [0.4819],\n",
            "        [0.4931],\n",
            "        [0.5043],\n",
            "        [0.5155],\n",
            "        [0.5267],\n",
            "        [0.5378],\n",
            "        [0.5490],\n",
            "        [0.5602],\n",
            "        [0.5714],\n",
            "        [0.5826],\n",
            "        [0.5938],\n",
            "        [0.6050],\n",
            "        [0.6162],\n",
            "        [0.6274],\n",
            "        [0.6385],\n",
            "        [0.6497],\n",
            "        [0.6609],\n",
            "        [0.6721],\n",
            "        [0.6833],\n",
            "        [0.6945],\n",
            "        [0.7057],\n",
            "        [0.7169],\n",
            "        [0.7281],\n",
            "        [0.7393],\n",
            "        [0.7504],\n",
            "        [0.7616],\n",
            "        [0.7728],\n",
            "        [0.7840],\n",
            "        [0.7952]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3583],\n",
            "        [0.3695],\n",
            "        [0.3808],\n",
            "        [0.3920],\n",
            "        [0.4032],\n",
            "        [0.4144],\n",
            "        [0.4257],\n",
            "        [0.4369],\n",
            "        [0.4481],\n",
            "        [0.4593],\n",
            "        [0.4706],\n",
            "        [0.4818],\n",
            "        [0.4930],\n",
            "        [0.5042],\n",
            "        [0.5155],\n",
            "        [0.5267],\n",
            "        [0.5379],\n",
            "        [0.5491],\n",
            "        [0.5604],\n",
            "        [0.5716],\n",
            "        [0.5828],\n",
            "        [0.5940],\n",
            "        [0.6053],\n",
            "        [0.6165],\n",
            "        [0.6277],\n",
            "        [0.6389],\n",
            "        [0.6502],\n",
            "        [0.6614],\n",
            "        [0.6726],\n",
            "        [0.6839],\n",
            "        [0.6951],\n",
            "        [0.7063],\n",
            "        [0.7175],\n",
            "        [0.7288],\n",
            "        [0.7400],\n",
            "        [0.7512],\n",
            "        [0.7624],\n",
            "        [0.7737],\n",
            "        [0.7849],\n",
            "        [0.7961]], grad_fn=<AddBackward0>)\n",
            "Epoch: 90 | MAE Train Loss: 0.02788739837706089 | MAE Test Loss: 0.06473556160926819 \n",
            "tensor([[0.3573],\n",
            "        [0.3686],\n",
            "        [0.3798],\n",
            "        [0.3911],\n",
            "        [0.4023],\n",
            "        [0.4136],\n",
            "        [0.4249],\n",
            "        [0.4361],\n",
            "        [0.4474],\n",
            "        [0.4586],\n",
            "        [0.4699],\n",
            "        [0.4811],\n",
            "        [0.4924],\n",
            "        [0.5037],\n",
            "        [0.5149],\n",
            "        [0.5262],\n",
            "        [0.5374],\n",
            "        [0.5487],\n",
            "        [0.5599],\n",
            "        [0.5712],\n",
            "        [0.5825],\n",
            "        [0.5937],\n",
            "        [0.6050],\n",
            "        [0.6162],\n",
            "        [0.6275],\n",
            "        [0.6387],\n",
            "        [0.6500],\n",
            "        [0.6613],\n",
            "        [0.6725],\n",
            "        [0.6838],\n",
            "        [0.6950],\n",
            "        [0.7063],\n",
            "        [0.7175],\n",
            "        [0.7288],\n",
            "        [0.7401],\n",
            "        [0.7513],\n",
            "        [0.7626],\n",
            "        [0.7738],\n",
            "        [0.7851],\n",
            "        [0.7963]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3568],\n",
            "        [0.3681],\n",
            "        [0.3794],\n",
            "        [0.3907],\n",
            "        [0.4020],\n",
            "        [0.4133],\n",
            "        [0.4246],\n",
            "        [0.4359],\n",
            "        [0.4472],\n",
            "        [0.4585],\n",
            "        [0.4697],\n",
            "        [0.4810],\n",
            "        [0.4923],\n",
            "        [0.5036],\n",
            "        [0.5149],\n",
            "        [0.5262],\n",
            "        [0.5375],\n",
            "        [0.5488],\n",
            "        [0.5601],\n",
            "        [0.5714],\n",
            "        [0.5827],\n",
            "        [0.5940],\n",
            "        [0.6053],\n",
            "        [0.6166],\n",
            "        [0.6279],\n",
            "        [0.6391],\n",
            "        [0.6504],\n",
            "        [0.6617],\n",
            "        [0.6730],\n",
            "        [0.6843],\n",
            "        [0.6956],\n",
            "        [0.7069],\n",
            "        [0.7182],\n",
            "        [0.7295],\n",
            "        [0.7408],\n",
            "        [0.7521],\n",
            "        [0.7634],\n",
            "        [0.7747],\n",
            "        [0.7860],\n",
            "        [0.7973]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3563],\n",
            "        [0.3676],\n",
            "        [0.3790],\n",
            "        [0.3903],\n",
            "        [0.4016],\n",
            "        [0.4130],\n",
            "        [0.4243],\n",
            "        [0.4356],\n",
            "        [0.4469],\n",
            "        [0.4583],\n",
            "        [0.4696],\n",
            "        [0.4809],\n",
            "        [0.4923],\n",
            "        [0.5036],\n",
            "        [0.5149],\n",
            "        [0.5263],\n",
            "        [0.5376],\n",
            "        [0.5489],\n",
            "        [0.5602],\n",
            "        [0.5716],\n",
            "        [0.5829],\n",
            "        [0.5942],\n",
            "        [0.6056],\n",
            "        [0.6169],\n",
            "        [0.6282],\n",
            "        [0.6395],\n",
            "        [0.6509],\n",
            "        [0.6622],\n",
            "        [0.6735],\n",
            "        [0.6849],\n",
            "        [0.6962],\n",
            "        [0.7075],\n",
            "        [0.7189],\n",
            "        [0.7302],\n",
            "        [0.7415],\n",
            "        [0.7528],\n",
            "        [0.7642],\n",
            "        [0.7755],\n",
            "        [0.7868],\n",
            "        [0.7982]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3553],\n",
            "        [0.3667],\n",
            "        [0.3780],\n",
            "        [0.3894],\n",
            "        [0.4008],\n",
            "        [0.4121],\n",
            "        [0.4235],\n",
            "        [0.4348],\n",
            "        [0.4462],\n",
            "        [0.4576],\n",
            "        [0.4689],\n",
            "        [0.4803],\n",
            "        [0.4916],\n",
            "        [0.5030],\n",
            "        [0.5144],\n",
            "        [0.5257],\n",
            "        [0.5371],\n",
            "        [0.5485],\n",
            "        [0.5598],\n",
            "        [0.5712],\n",
            "        [0.5825],\n",
            "        [0.5939],\n",
            "        [0.6053],\n",
            "        [0.6166],\n",
            "        [0.6280],\n",
            "        [0.6393],\n",
            "        [0.6507],\n",
            "        [0.6621],\n",
            "        [0.6734],\n",
            "        [0.6848],\n",
            "        [0.6961],\n",
            "        [0.7075],\n",
            "        [0.7189],\n",
            "        [0.7302],\n",
            "        [0.7416],\n",
            "        [0.7530],\n",
            "        [0.7643],\n",
            "        [0.7757],\n",
            "        [0.7870],\n",
            "        [0.7984]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3548],\n",
            "        [0.3662],\n",
            "        [0.3776],\n",
            "        [0.3890],\n",
            "        [0.4004],\n",
            "        [0.4118],\n",
            "        [0.4232],\n",
            "        [0.4346],\n",
            "        [0.4460],\n",
            "        [0.4574],\n",
            "        [0.4688],\n",
            "        [0.4802],\n",
            "        [0.4916],\n",
            "        [0.5030],\n",
            "        [0.5144],\n",
            "        [0.5258],\n",
            "        [0.5372],\n",
            "        [0.5486],\n",
            "        [0.5600],\n",
            "        [0.5714],\n",
            "        [0.5828],\n",
            "        [0.5942],\n",
            "        [0.6055],\n",
            "        [0.6169],\n",
            "        [0.6283],\n",
            "        [0.6397],\n",
            "        [0.6511],\n",
            "        [0.6625],\n",
            "        [0.6739],\n",
            "        [0.6853],\n",
            "        [0.6967],\n",
            "        [0.7081],\n",
            "        [0.7195],\n",
            "        [0.7309],\n",
            "        [0.7423],\n",
            "        [0.7537],\n",
            "        [0.7651],\n",
            "        [0.7765],\n",
            "        [0.7879],\n",
            "        [0.7993]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3538],\n",
            "        [0.3652],\n",
            "        [0.3767],\n",
            "        [0.3881],\n",
            "        [0.3995],\n",
            "        [0.4110],\n",
            "        [0.4224],\n",
            "        [0.4338],\n",
            "        [0.4452],\n",
            "        [0.4567],\n",
            "        [0.4681],\n",
            "        [0.4795],\n",
            "        [0.4910],\n",
            "        [0.5024],\n",
            "        [0.5138],\n",
            "        [0.5252],\n",
            "        [0.5367],\n",
            "        [0.5481],\n",
            "        [0.5595],\n",
            "        [0.5710],\n",
            "        [0.5824],\n",
            "        [0.5938],\n",
            "        [0.6052],\n",
            "        [0.6167],\n",
            "        [0.6281],\n",
            "        [0.6395],\n",
            "        [0.6510],\n",
            "        [0.6624],\n",
            "        [0.6738],\n",
            "        [0.6853],\n",
            "        [0.6967],\n",
            "        [0.7081],\n",
            "        [0.7195],\n",
            "        [0.7310],\n",
            "        [0.7424],\n",
            "        [0.7538],\n",
            "        [0.7653],\n",
            "        [0.7767],\n",
            "        [0.7881],\n",
            "        [0.7995]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3533],\n",
            "        [0.3648],\n",
            "        [0.3762],\n",
            "        [0.3877],\n",
            "        [0.3992],\n",
            "        [0.4106],\n",
            "        [0.4221],\n",
            "        [0.4336],\n",
            "        [0.4450],\n",
            "        [0.4565],\n",
            "        [0.4680],\n",
            "        [0.4794],\n",
            "        [0.4909],\n",
            "        [0.5024],\n",
            "        [0.5138],\n",
            "        [0.5253],\n",
            "        [0.5367],\n",
            "        [0.5482],\n",
            "        [0.5597],\n",
            "        [0.5711],\n",
            "        [0.5826],\n",
            "        [0.5941],\n",
            "        [0.6055],\n",
            "        [0.6170],\n",
            "        [0.6285],\n",
            "        [0.6399],\n",
            "        [0.6514],\n",
            "        [0.6629],\n",
            "        [0.6743],\n",
            "        [0.6858],\n",
            "        [0.6973],\n",
            "        [0.7087],\n",
            "        [0.7202],\n",
            "        [0.7317],\n",
            "        [0.7431],\n",
            "        [0.7546],\n",
            "        [0.7661],\n",
            "        [0.7775],\n",
            "        [0.7890],\n",
            "        [0.8004]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3523],\n",
            "        [0.3638],\n",
            "        [0.3753],\n",
            "        [0.3868],\n",
            "        [0.3983],\n",
            "        [0.4098],\n",
            "        [0.4213],\n",
            "        [0.4328],\n",
            "        [0.4443],\n",
            "        [0.4558],\n",
            "        [0.4673],\n",
            "        [0.4788],\n",
            "        [0.4903],\n",
            "        [0.5018],\n",
            "        [0.5133],\n",
            "        [0.5248],\n",
            "        [0.5363],\n",
            "        [0.5478],\n",
            "        [0.5593],\n",
            "        [0.5707],\n",
            "        [0.5822],\n",
            "        [0.5937],\n",
            "        [0.6052],\n",
            "        [0.6167],\n",
            "        [0.6282],\n",
            "        [0.6397],\n",
            "        [0.6512],\n",
            "        [0.6627],\n",
            "        [0.6742],\n",
            "        [0.6857],\n",
            "        [0.6972],\n",
            "        [0.7087],\n",
            "        [0.7202],\n",
            "        [0.7317],\n",
            "        [0.7432],\n",
            "        [0.7547],\n",
            "        [0.7662],\n",
            "        [0.7777],\n",
            "        [0.7892],\n",
            "        [0.8007]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3518],\n",
            "        [0.3633],\n",
            "        [0.3749],\n",
            "        [0.3864],\n",
            "        [0.3979],\n",
            "        [0.4095],\n",
            "        [0.4210],\n",
            "        [0.4325],\n",
            "        [0.4441],\n",
            "        [0.4556],\n",
            "        [0.4671],\n",
            "        [0.4787],\n",
            "        [0.4902],\n",
            "        [0.5017],\n",
            "        [0.5133],\n",
            "        [0.5248],\n",
            "        [0.5363],\n",
            "        [0.5479],\n",
            "        [0.5594],\n",
            "        [0.5709],\n",
            "        [0.5825],\n",
            "        [0.5940],\n",
            "        [0.6055],\n",
            "        [0.6171],\n",
            "        [0.6286],\n",
            "        [0.6401],\n",
            "        [0.6517],\n",
            "        [0.6632],\n",
            "        [0.6747],\n",
            "        [0.6863],\n",
            "        [0.6978],\n",
            "        [0.7093],\n",
            "        [0.7209],\n",
            "        [0.7324],\n",
            "        [0.7439],\n",
            "        [0.7555],\n",
            "        [0.7670],\n",
            "        [0.7785],\n",
            "        [0.7901],\n",
            "        [0.8016]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the loss curves\n",
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sksNn6-cis7d",
        "outputId": "4f78ac10-5516-4422-dc9f-c5c29e70f373"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using state_dict() to see how close our model gets to the orignal values for weights and biases\n",
        "# Find our model's learned parameters\n",
        "print(\"The model learned the following values for weights and bias:\")\n",
        "print(model_0.state_dict())\n",
        "print(\"\\nAnd the original values for weights and bias are:\")\n",
        "print(f\"weights: {weight}, bias: {bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAfBYBhTis6E",
        "outputId": "7dc147e2-3174-4f50-86d9-31a2a8b62c36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model learned the following values for weights and bias:\n",
            "OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])\n",
            "\n",
            "And the original values for weights and bias are:\n",
            "weights: 0.7, bias: 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAKING PREDICTIONS WITH A TRAINED MODEL PYTROCH MODEL (INFERENCE)\n",
        "#SETTING THE MODEL IN EVALUATION MODE\n",
        "model_0.eval()\n",
        "#setup the inference mode context manager\n",
        "with torch.inference_mode():\n",
        "  y_preds= model_0(X_test)\n",
        "y_pred\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ7lkqTHis2x",
        "outputId": "855e18e7-0eae-4821-bc72-21edd5abf693"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3518],\n",
              "        [0.3633],\n",
              "        [0.3749],\n",
              "        [0.3864],\n",
              "        [0.3979],\n",
              "        [0.4095],\n",
              "        [0.4210],\n",
              "        [0.4325],\n",
              "        [0.4441],\n",
              "        [0.4556],\n",
              "        [0.4671],\n",
              "        [0.4787],\n",
              "        [0.4902],\n",
              "        [0.5017],\n",
              "        [0.5133],\n",
              "        [0.5248],\n",
              "        [0.5363],\n",
              "        [0.5479],\n",
              "        [0.5594],\n",
              "        [0.5709],\n",
              "        [0.5825],\n",
              "        [0.5940],\n",
              "        [0.6055],\n",
              "        [0.6171],\n",
              "        [0.6286],\n",
              "        [0.6401],\n",
              "        [0.6517],\n",
              "        [0.6632],\n",
              "        [0.6747],\n",
              "        [0.6863],\n",
              "        [0.6978],\n",
              "        [0.7093],\n",
              "        [0.7209],\n",
              "        [0.7324],\n",
              "        [0.7439],\n",
              "        [0.7555],\n",
              "        [0.7670],\n",
              "        [0.7785],\n",
              "        [0.7901],\n",
              "        [0.8016]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HOW DO THESE PREDICTIONS LOOK LIKE?\n",
        "plot_predictions(predictions= y_preds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "DcnNCvGdis0r",
        "outputId": "86a85134-6394-47ce-ffa6-9328c13bd1b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "he7TSTF7iswz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1y_gsYWCisvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-g9dQTpIifhB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0MmsHaxWEBE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FD0EcWo1WD9b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3ig4Ab2WD77"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}